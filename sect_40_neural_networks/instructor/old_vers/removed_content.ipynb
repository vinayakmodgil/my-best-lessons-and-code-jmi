{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IA6ZLbuoQv8D"
   },
   "source": [
    "## Deeper Neural Networks:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hHZ0q-QYomgR"
   },
   "source": [
    "       \n",
    "- **Advantages:**\n",
    "    - largely eliminates need for feature engineering\n",
    "    - multiple levels of information processing in one networking.\n",
    "        - Ex: for images:\n",
    "            - First layer detects edges\n",
    "            - second layer gorups edges and detects patterns\n",
    "            - more layers group even bigger parts together\n",
    "        - Ex: for audio:\n",
    "            - first layer: low level wave features\n",
    "            - second: basic units of sounds (\"phonemes\")\n",
    "            - third: word recognition\n",
    "            - fourth: sentence recognition\n",
    "    \n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-04-40-04-deeper-neural-networks-online-ds-ft-021119/master/figures/small_deeper.png\">\n",
    "\n",
    "- Networks are comprised of sequential layers of neurons/nodes.\n",
    "    - \\# of layers = hidden+output layer\n",
    "        - The input layer is not counted as formal layer.\n",
    "    - All layers except the final are _hidden layers_.\n",
    "\n",
    "\n",
    "### NOTATION:\n",
    "Generally, the output of layer $j$ is denoted as $a^{[j]}$.\n",
    "\n",
    "**For our 2-layer neural network above, this means that:**\n",
    "\n",
    "- $x = a^{[0]}$  as x is what comes out of the input layer\n",
    "- $a^{[1]} = \\begin{bmatrix} a^{[1]}_1  \\\\ a^{[1]}_2 \\\\ a^{[1]}_3  \\\\\\end{bmatrix}$ is the value generated by the hidden layer\n",
    "- $\\hat y =  a^{[2]}$, the output layer will generate a value $a^{[2]}$, which is equal to $\\hat y$.\n",
    "\n",
    "\n",
    "<br>For the **first node** in the hidden layer:\n",
    "- The linear transformation that occurs is:  $ z^{[1]}_1 = w^{[1]}_1 x +b^{[1]}_1$,\n",
    "    - Where $w$ = the weight, and $b$ = bias\n",
    "\n",
    "- For **all nodes** in the hidden layer:\n",
    "    - $ z^{[1]}_1 = w^{[1]}_1 x +b^{[1]}_1$ and  $a^{[1]}_1= f(z^{[1]}_1)$\n",
    "\n",
    "    - $ z^{[1]}_2 = w^{[1]}_2 x +b^{[1]}_2$ and $a^{[1]}_2= f(z^{[1]}_2)$\n",
    "\n",
    "    - $ z^{[1]}_3 = w^{[1]}_3 x +b^{[1]}_3$ and $a^{[1]}_3= f(z^{[1]}_3)$\n",
    "\n",
    "The **dimensions** of the elements:\n",
    "\n",
    "- $w^{[1]} = \\begin{bmatrix} w^{[1]}_{1,1}  & w^{[1]}_{2,1} & w^{[1]}_{3,1}  \\\\ w^{[1]}_{1,2}  & w^{[1]}_{2,2} & w^{[1]}_{3,2}\\end{bmatrix}$\n",
    "    - where, eg. $w^{[1]}_{1,2}$ denotes the weight of the arrow going **from $x_2$ into the first node** of the hidden layer. \n",
    "\n",
    "\n",
    "- When multiplying the transpose of this matrix (making it a 2 x 3 matrix) \n",
    "    - $w^{[1]T}_1$ with $x = \\begin{bmatrix} x_1  \\\\x_2\\end{bmatrix}$ and add $b^{[1]} = \\begin{bmatrix} b^{[1]}_1  \\\\b^{[1]}_2 \\\\ b^{[1]}_3 \\end{bmatrix}$,\n",
    "    - we obtain $z^{[1]} = \\begin{bmatrix} z^{[1]}_1  \\\\z^{[1]}_2 \\\\ z^{[1]}_3 \\end{bmatrix}$.\n",
    "\n",
    "----\n",
    "\n",
    "- The activation function is   $a^{[1]}_1= f(z^{[1]}_1)$.\n",
    "$w^{[1]}_{1,2}$\n",
    "\n",
    "$w^{[1]} = \\begin{bmatrix} w^{[1]}_{1,1}  & w^{[1]}_{2,1} & w^{[1]}_{3,1}  \\\\ w^{[1]}_{1,2}  & w^{[1]}_{2,2} & w^{[1]}_{3,2}\\end{bmatrix}$ \n",
    "\n",
    "[Reminder: $x = \\begin{bmatrix} x_1  \\\\x_2\\end{bmatrix} \\equiv a^{[0]}$ and that $a^{[2]} = \\hat y$ ]\n",
    "\n",
    "- Then, given input $x$:\n",
    "\n",
    "    - $z^{[1]} = w^{[1]T} a^{[0]} + b^{[1]}$\n",
    "\n",
    "    - $a^{[1]} = f(z^{[1]})$\n",
    "\n",
    "    - $z^{[2]} = w^{[2]T} a^{[1]} + b^{[2]}$\n",
    "\n",
    "    - $a^{[2]} = f(z^{[1]})$\n",
    "    \n",
    "    \n",
    "- When adding in several training samples ($i$), these become:\n",
    "    - $z^{[1](i)} = w^{[1]T} a^{[0](i)} + b^{[0]}$\n",
    "\n",
    "    - $a^{[1](i)} = f(z^{[1](i)})$\n",
    "\n",
    "    - $z^{[2](i)} = w^{[2]T} a^{[1](i)} + b^{[2]}$\n",
    "\n",
    "    - $a^{[2](i)} = f(z^{[1](i)})$\n",
    "    \n",
    "    \n",
    "### Process Summary\n",
    "- We begin by defining a model architecture which includes the number of hidden layers, activation functions (sigmoid or relu) and the number of units in each of these.  \n",
    "- We then initialize parameters for each of these layers (typically randomly). After the initial parameters are set, forward propagation evaluates the model giving a prediction, which is then used to evaluate a cost function. Forward propogation involves evaluating each layer and then piping this output into the next layer. \n",
    "- Each layer consists of a linear transformation and an activation function.  The parameters for the linear transformation in **each** layer include $W^l$ and $b^l$. The output of this linear transformation is represented by $Z^l$. This is then fed through the activation function (again, for each layer) giving us an output $A^l$ which is the input for the next layer of the model.  \n",
    "- After forward propogation is completed and the cost function is evaluated, backpropogation is used to calculate gradients of the initial parameters with respect to this cost function. Finally, these gradients are then used in an optimization algorithm, such as gradient descent, to make small adjustments to the parameters and the entire process of forward propogation, back propogation and parameter adjustments is repeated until the modeller is satisfied with the results.\n",
    "\n",
    "\n",
    "### Parameter Summary (Deep Networks Lesson):\n",
    "Notation for when there are $L$ layers present (and $l$ is current layer)\n",
    "\n",
    "**Parameters for the linear transformation: **  \n",
    "\n",
    "$W^{[l]}: (n^{[l]}, n^{[l-1]})$\n",
    "\n",
    "$b^{[l]}: (n^{[l]}, 1)$\n",
    "\n",
    "$dW^{[l]}: (n^{[l]}, n^{[l-1]})$\n",
    "\n",
    "$db^{[l]}: (n^{[l]}, 1)$\n",
    "\n",
    "**Parameters for the activation function**  \n",
    "\n",
    "$ a^{[l]}, z^{[l]}: (n^{[l]}, 1)$\n",
    "\n",
    "$ Z^{[l]}, A^{[l]}: (n^{[l]}, m)$\n",
    "\n",
    "$ dZ^{[l]}, dA^{[l]}: (n^{[l]}, m)$\n",
    "\n",
    "\n",
    "\n",
    "### Forward propagation:\n",
    "- Process: \n",
    "    - evaluating a cost function associated with the output of the neural network by successively calculating the output of each layer given initial parameter values, and passing this output on to the next layer until a finalized output has been calculated and the cost function can then be evaluated..\n",
    "        - Input is $a^{[l-1]}$\n",
    "        - Output $a^{[l]}$, save $z^{[l]}, w^{[l]}, b^{[l]}, a^{[l-1]} $\n",
    "    \n",
    "- $Z^1$ is the output of the linear transformation of the initial input $A^1$ (the observations).\n",
    "- In successive layers, $A^l$ is the output from the previous hidden layer. \n",
    "- In all of these cases, $W^l$ is a matrix of weights to be optimized minimize the cost function. $b^l$ is also optimized but is a vector as opposed to a matrix.  \n",
    "\n",
    "- $g^l$ is the activation function which takes the output of this linear transformation and yields the input to the next hidden layer.  \n",
    "- $ Z^{[l]}= W^{[l]} A^{[l-1]} + b^{[l]}$\n",
    "\n",
    "- $ A^{[l]}= g^{[l]} ( Z^{[l]})$\n",
    "\n",
    "- Shape: here, $ Z^{[l]}, A^{[l]}$ both have a shape of $(n^{[l]}, m)$\n",
    "\n",
    "    - where $n$ the nodes in the layer $l$\n",
    "    \n",
    "    \n",
    "### Backward Propagation:\n",
    "- Once an output for the neural network given the current parameter weights has been calculated, we must back propogate to calculate the gradients of layer parameters with respect to the cost function.\n",
    "    - This will allow us to apply an optimization algorithm such as gradient descent in order to make small adjustments to the parameters in order to minimize our cost (and improve our predictions).\n",
    "    - Input $da ^{[l]}$\n",
    "    - Output $da^{[l-1]}$, $dW^{[l]}, db^{[l]}$\n",
    "\n",
    "\n",
    "- **The gradients for our respective parameters are given by:**\n",
    "   \n",
    "    - $ dZ^{[l]}= dA ^{[l]} * g^{[l]'} (Z^{[l]})$\n",
    "\n",
    "    - $ dW^{[l]} = \\dfrac{1}{m} dZ^{[l]}* A^{[l-1]T}$\n",
    "\n",
    "    - $ db^{[l]} = \\dfrac{1}{m} np.sum(dZ^{[l]}, axis=1, keepdims=True)$\n",
    "\n",
    "    - $ dA^{[l-1]} = W^{[l]T}*dZ^{[l]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JkJpdZlv3VNe"
   },
   "source": [
    "## Intro to Keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LYecj1xvmvEU"
   },
   "source": [
    "### Keras Basics\n",
    "- Tensors dimensions:\n",
    "    - Scalars = 0D tensors\n",
    "    - Vectors = 1D tensors\n",
    "    - Matrices = 2D tensors\n",
    "    - 3D tensors\n",
    "- A tensor is defined by 3 characteristics:\n",
    "    - rank or number of axes\n",
    "    - the shape\n",
    "    - the data type\n",
    "- Tensor basics - properties (from [here](https://pgaleone.eu/tensorflow/2018/07/28/understanding-tensorflow-tensors-shape-static-dynamic/#tensors-the-basic)):\n",
    "    - name\n",
    "    - type:\n",
    "        - tf.float32, tf.int64, tf.string\n",
    "    - rank:\n",
    "        - the number of dimension or the tensor. \n",
    "        - scalar = 0, vector = 1, etc.\n",
    "    - shape:\n",
    "\n",
    "### Important Data Manipulations in numpy\n",
    "\n",
    "- **Unrowing matrices:**\n",
    "    - e.g. turning a matrix of 790 images, which are 64 x 64 pixels and in RBG (3 colors) a (790, 64, 64, 3) matrix  into a matrix with 1 row for each image a ( 64*64*3, 790) matrix\n",
    "    - img_unrow = img.reshape(790, -1).T\n",
    "        - reshape -1 essentially means \"figure out how many, based upon the dat'\n",
    "- **Increasing the rank:**\n",
    "    - Vector with `np.shape()` returns  `(790,)`\n",
    "    - `np.reshape(vector, (1, 790))`\n",
    "- **Tensor indexling/slicing**\n",
    "    - just as python, `tensor[start_idx : end_idx]`\n",
    "    - left inclusive, right exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:06:06.950877Z",
     "start_time": "2020-02-12T00:06:00.483201Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "NbbVDhN0rDhV",
    "outputId": "4b5f722d-e72f-42bd-905b-b965aee215f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Tensor shape: (60000, 28, 28)\n",
      "Tensor Slice [0:100] shape: (100, 28, 28)\n",
      "Tensor Slice [0:100] shape: (100, 28, 28)\n",
      "Tensor Slice [0:100] shape: (100, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAANn0lEQVR4nO3df6hc9ZnH8c9nsw2CrZI0lxDjj9utAZWF1TKElcaStawY//C3okJ1JZCKRiupoHSDVUGQsFUWWarpKs2u3WghFX8gbjUUJH9YnOg1iYmr2eTGGqO5KiEJaNzYZ/+4x3I1d87czJmZM97n/YLLzJxnzvk+jH5y5p7vzP06IgRg+vuruhsA0B+EHUiCsANJEHYgCcIOJPHX/Rxszpw5MTw83M8hgVRGR0f14YcferJapbDbPl/Sv0qaIenfI+K+sucPDw+r2WxWGRJAiUaj0bLW8dt42zMk/ZukJZLOkHS17TM6PR6A3qryO/tCSdsjYkdEfCbpcUkXdactAN1WJezzJf1pwuN3i21fYnuZ7abt5tjYWIXhAFTR86vxEbE6IhoR0RgaGur1cABaqBL23ZJOmvD4xGIbgAFUJeyvSFpg+zu2Z0q6StLT3WkLQLd1PPUWEYdtL5f03xqfens0It7oWmcAuqrSPHtEPCfpuS71AqCH+LgskARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0n0dclm9MbWrVtb1p599tnSfR9++OHS+sKFC0vrZ511Vmm9zK233lpanzlzZsfHxpE4swNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEsyzfw20mwu/7bbbWtYOHjxYaewdO3aU1h9//PGOj91oNErr5557bsfHxpEqhd32qKQDkj6XdDgiyv/rAahNN87s/xARH3bhOAB6iN/ZgSSqhj0k/d72RtvLJnuC7WW2m7abY2NjFYcD0KmqYV8UEd+TtETSTbZ/8NUnRMTqiGhERGNoaKjicAA6VSnsEbG7uN0r6UlJ5V+RAlCbjsNu+1jb3/rivqTzJG3pVmMAuqvK1fi5kp60/cVx/isinu9KV/iSK664orR+5513tqxVnWfvpcsuu6y0/sQTT5TWzzvvvG62M+11HPaI2CHp77rYC4AeYuoNSIKwA0kQdiAJwg4kQdiBJPiK69fA7NmzS+t33313y9qKFStK9/3kk09K6yeffHJp/Z133imtl9m3b19p/fnny2dymXo7OpzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJ5tmngRtuuKFl7aGHHird9/XXXy+tH3fccR311A3Lly+vbezpiDM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBPPs0t3LlytL6vffeW1ofGRnpZjtH5dChQ7WNPR1xZgeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJJhnn+Yuv/zy0vqiRYtK6+3+NvvmzZuPuqepavcZgXXr1vVs7Omo7Znd9qO299reMmHbbNsv2H67uJ3V2zYBVDWVt/G/lnT+V7bdIWl9RCyQtL54DGCAtQ17RLwk6eOvbL5I0pri/hpJF3e5LwBd1ukFurkRsae4/76kua2eaHuZ7abt5tjYWIfDAaiq8tX4iAhJUVJfHRGNiGgMDQ1VHQ5AhzoN+we250lScbu3ey0B6IVOw/60pOuK+9dJeqo77QDolbbz7LbXSlosaY7tdyX9XNJ9kn5re6mkXZKu7GWT6Nxjjz1WWt+0aVNpvZfz6O2cc845tY09HbUNe0Rc3aL0wy73AqCH+LgskARhB5Ig7EAShB1IgrADSfAV16+BN998s7R+ySWXtKxt3769dN/Dhw931FM/XHjhhXW3MK1wZgeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJJhn/xrYtm1baX3nzp0ta4M8j97OAw88UFp/8MEH+9TJ9MCZHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJ79a6Ds++qStGrVqpa122+/vXTfTz/9tKOe+uG9996ru4VphTM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBPPs0cMstt7SsLViwoHTfffv2VRq73fflly9f3rK2f//+SmPj6LQ9s9t+1PZe21smbLvL9m7bI8XPBb1tE0BVU3kb/2tJ50+y/YGIOLP4ea67bQHotrZhj4iXJH3ch14A9FCVC3TLbW8q3ubPavUk28tsN203x8bGKgwHoIpOw/5LSd+VdKakPZJ+0eqJEbE6IhoR0RgaGupwOABVdRT2iPggIj6PiD9L+pWkhd1tC0C3dRR22/MmPLxE0pZWzwUwGNrOs9teK2mxpDm235X0c0mLbZ8pKSSNSvpxD3tEBUuWLOnp8SOitF62Pvw999xTuu/IyEhpfdeuXaX1U045pbSeTduwR8TVk2x+pAe9AOghPi4LJEHYgSQIO5AEYQeSIOxAEnzFFZV89tlnpfV202tlZs6cWVqfMWNGx8fOiDM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBPDsqWblyZc+OvXTp0tL6iSee2LOxpyPO7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBPPsU/TRRx+1rF1//fWl+1511VWl9Wuuuaajnvphz549pfXVq1f3bOxLL720Z8fOiDM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBPPsU3XzzzS1rzzzzTOm+b731Vml9/vz5leqnnnpqy9rGjRtL923X26pVq0rr+/fvL62XWbFiRWn9hBNO6PjYOFLbM7vtk2z/wfZW22/Y/kmxfbbtF2y/XdzO6n27ADo1lbfxhyX9NCLOkPT3km6yfYakOyStj4gFktYXjwEMqLZhj4g9EfFqcf+ApG2S5ku6SNKa4mlrJF3cqyYBVHdUF+hsD0s6S9IfJc2NiC8+OP2+pLkt9llmu2m7OTY2VqFVAFVMOey2vylpnaRbI+JLV2UiIiTFZPtFxOqIaEREY2hoqFKzADo3pbDb/obGg/6biPhdsfkD2/OK+jxJe3vTIoBuaDv1ZtuSHpG0LSLun1B6WtJ1ku4rbp/qSYcDomzqbefOnaX7vvzyy6X1xYsXl9aHh4dL66effnrL2oYNG0r3PXDgQGm9qtNOO61lrd1yzsccc0y320ltKvPs35f0I0mbbY8U236m8ZD/1vZSSbskXdmbFgF0Q9uwR8QGSW5R/mF32wHQK3xcFkiCsANJEHYgCcIOJEHYgST4iusUnX322R3VJOnaa68trd94442l9dHR0Ur1Xpo1q/zLjtu2betTJ2iHMzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME8exfcf//9pfVDhw6V1g8ePFhp/Ndee61lbe3atZWOffzxx5fWX3zxxUrHR/9wZgeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJDy+mEt/NBqNaDabfRsPyKbRaKjZbE7616A5swNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEm3Dbvsk23+wvdX2G7Z/Umy/y/Zu2yPFzwW9bxdAp6byxysOS/ppRLxq+1uSNtp+oag9EBH/0rv2AHTLVNZn3yNpT3H/gO1tkub3ujEA3XVUv7PbHpZ0lqQ/FpuW295k+1Hbk64DZHuZ7abt5tjYWKVmAXRuymG3/U1J6yTdGhH7Jf1S0nclnanxM/8vJtsvIlZHRCMiGkNDQ11oGUAnphR229/QeNB/ExG/k6SI+CAiPo+IP0v6laSFvWsTQFVTuRpvSY9I2hYR90/YPm/C0y6RtKX77QHolqlcjf++pB9J2mx7pNj2M0lX2z5TUkgalfTjnnQIoCumcjV+g6TJvh/7XPfbAdArfIIOSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQRF+XbLY9JmnXhE1zJH3YtwaOzqD2Nqh9SfTWqW72dkpETPr33/oa9iMGt5sR0aitgRKD2tug9iXRW6f61Rtv44EkCDuQRN1hX13z+GUGtbdB7Uuit071pbdaf2cH0D91n9kB9AlhB5KoJey2z7f9P7a3276jjh5asT1qe3OxDHWz5l4etb3X9pYJ22bbfsH228XtpGvs1dTbQCzjXbLMeK2vXd3Ln/f9d3bbMyS9JekfJb0r6RVJV0fE1r420oLtUUmNiKj9Axi2fyDpoKT/iIi/LbatkvRxRNxX/EM5KyJuH5De7pJ0sO5lvIvViuZNXGZc0sWS/kk1vnYlfV2pPrxudZzZF0raHhE7IuIzSY9LuqiGPgZeRLwk6eOvbL5I0pri/hqN/8/Sdy16GwgRsSciXi3uH5D0xTLjtb52JX31RR1hny/pTxMev6vBWu89JP3e9kbby+puZhJzI2JPcf99SXPrbGYSbZfx7qevLDM+MK9dJ8ufV8UFuiMtiojvSVoi6abi7epAivHfwQZp7nRKy3j3yyTLjP9Fna9dp8ufV1VH2HdLOmnC4xOLbQMhInYXt3slPanBW4r6gy9W0C1u99bcz18M0jLeky0zrgF47epc/ryOsL8iaYHt79ieKekqSU/X0McRbB9bXDiR7WMlnafBW4r6aUnXFfevk/RUjb18yaAs491qmXHV/NrVvvx5RPT9R9IFGr8i/7+S/rmOHlr09TeSXi9+3qi7N0lrNf627v80fm1jqaRvS1ov6W1JL0qaPUC9/aekzZI2aTxY82rqbZHG36JvkjRS/FxQ92tX0ldfXjc+LgskwQU6IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUji/wFmMiW1uRejmAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tensor indexing example using images\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "digit = train_images[10] #Select an arbitrary case for our example\n",
    "\n",
    "#Checking the shape of our tensor (in this case, the image)\n",
    "print('Raw Tensor shape:', train_images.shape)\n",
    "\n",
    "#Now performing some slices of our image:\n",
    "print('Tensor Slice [0:100] shape:', train_images[:100].shape)\n",
    "\n",
    "#Equivalently\n",
    "print('Tensor Slice [0:100] shape:', train_images[:100, :, :].shape)\n",
    "\n",
    "#Or verbosely:\n",
    "print('Tensor Slice [0:100] shape:', train_images[:100, :28, :28].shape)\n",
    "\n",
    "\n",
    "plt.imshow(digit, cmap=plt.cm.binary) #Display an example image for context\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:06:07.117356Z",
     "start_time": "2020-02-12T00:06:06.952313Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "6f_oIbrIrpn2",
    "outputId": "984d6db8-36d0-442f-bc7e-d98875c159fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sliced tensor shape (includes all images but only the lower right hand corner of each: (60000, 14, 14)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAME0lEQVR4nO3df6jldZ3H8edr7zSVYzQzu4OkV3QQUQZpNS5htbSLujBN4oTsHw4Zugn7z7pZBqEoxArCQhEFG8Vglmyif6htItU6WhELm3TVwVXHmlnzx9jYXIltov6YufTeP84xrrdR2/P9nu89+nk+4HLP93vO577f9zKv+f443+/5pKqQ9Ob3Z2vdgKRhGHapEYZdaoRhlxph2KVGrBuyWJImT/1v3Lix0/gzzjijp070ZvfMM8/w0ksv5XjPDRr2Vl1wwQWdxt999909daI3u4WFhVd9zt14qRGGXWqEYZca0SnsSbYn+WmSA0mu66spSf2bOOxJ5oAvAx8CtgG7kmzrqzFJ/eqyZX8vcKCqnq6qo8CdwM5+2pLUty5hPwV4fsXywfG6V0jyD0kWkyx2qCWpo6m/z15Vu4Hd0O5FNdIs6LJlfwE4dcXy/HidpBnUJew/Ac5MsjXJeuAy4N5+2pLUt4l346tqOcnVwH8Ac8CtVfVEb51J6lWnY/aq+g7wnZ56kTRFXkEnNcKwS40Y9BbXrVu3cvPNN088fnl5eeKxV1999cRjAY4cOdJpvLTW3LJLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiMGvcV18+bN7Nq1a+LxVZN/OO2BAwcmHgtw0003TTx27969nWo/++yzE4897bTTOtXWm4dbdqkRhl1qhGGXGmHYpUZ0mcX11CQ/SPJkkieSXNNnY5L61eVs/DLw6ap6JMk7gIeT7KmqJ3vqTVKPJt6yV9Whqnpk/Pg3wD6OM4urpNnQyzF7ktOB84CHjvPcH6ZsXlpa6qOcpAl0DnuSE4G7gU9W1R99uHpV7a6qhapa2LJlS9dykibUKexJ3sIo6LdX1T39tCRpGrqcjQ/wNWBfVX2hv5YkTUOXLfsHgI8BFyTZO/7a0VNfknrWZX72/wTSYy+Spsgr6KRGGHapEYPez97V0aNHJx7b5X70rtavX99p/NzcXE+dqGVu2aVGGHapEYZdaoRhlxph2KVGGHapEYZdaoRhlxph2KVGGHapEYZdaoRhlxph2KVGGHapEW+oW1xvvPHGtW5hIldddVWn8fPz8z11opa5ZZcaYdilRhh2qRGGXWpEH9M/zSV5NMl9fTQkaTr62LJfw2gGV0kzrOtcb/PAh4Fb+mlH0rR03bJ/EfgM8PtXe4FTNkuzocvEjhcDh6vq4dd6nVM2S7Oh68SOlyR5BriT0QSP3+ylK0m9mzjsVXV9Vc1X1enAZcD3q+ry3jqT1CvfZ5ca0cuNMFX1Q+CHffwsSdPhll1qhGGXGjHo/ezHjh3j0KFDE4/fvXt3j90M59JLL13rFiS37FIrDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUiEFvcd2/fz87duyYePyRI0d67Ob/59prr5147Mknn9xjJ9Jk3LJLjTDsUiMMu9QIwy41ouvEjhuT3JXkqST7kryvr8Yk9avr2fgvAd+rqr9Lsh44oYeeJE3BxGFP8k7gg8CVAFV1FDjaT1uS+tZlN34rsAR8PcmjSW5JsmH1i1ZO2by8vNyhnKQuuoR9HfAe4CtVdR7wW+C61S9aOWXzunWDXsMjaYUuYT8IHKyqh8bLdzEKv6QZ1GXK5heB55OcNV51IfBkL11J6l3X/ep/Am4fn4l/Gvj77i1JmoZOYa+qvcBCT71ImiKvoJMaYdilRqSqhiuWDFdslbPPPrvT+MXFxYnHbtjwR5cfSFOxsLDA4uJijvecW3apEYZdaoRhlxph2KVGGHapEYZdaoRhlxph2KVGGHapEYZdaoRhlxph2KVGGHapEYZdaoRhlxrxhvps502bNk08dt++fT12Ir3xuGWXGmHYpUYYdqkRXads/lSSJ5I8nuSOJG/rqzFJ/Zo47ElOAT4BLFTVOcAccFlfjUnqV9fd+HXA25OsYzQ3+y+6tyRpGrrM9fYC8HngOeAQ8Ouqun/161ZO2Tx5m5K66rIbvwnYyWie9pOBDUkuX/26lVM2T96mpK667MZfBPy8qpaq6hhwD/D+ftqS1LcuYX8OOD/JCUnCaMpmL1OTZlSXY/aHgLuAR4D/Hv+s3T31JalnXads/izw2Z56kTRFXkEnNcKwS40Y9BbXubk5TjzxxInHP/DAAz12I7XFLbvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40Y9H72c889l8VFPz5eWgtu2aVGGHapEYZdasTrhj3JrUkOJ3l8xbrNSfYk2T/+vmm6bUrq6k/Zsn8D2L5q3XXAg1V1JvDgeFnSDHvdsFfVj4BfrVq9E7ht/Pg24CM99yWpZ5Mes59UVYfGj18ETnq1F66csnlpaWnCcpK66nyCrqoKqNd4/g9TNm/ZsqVrOUkTmjTsv0zyLoDx98P9tSRpGiYN+73AFePHVwDf7qcdSdPyp7z1dgfwX8BZSQ4muQr4F+Bvk+wHLhovS5phr3ttfFXtepWnLuy5F0lT5BV0UiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9SISads/lySp5I8luRbSTZOt01JXU06ZfMe4JyqejfwM+D6nvuS1LOJpmyuqvuranm8+GNgfgq9SepRH8fsHwe+28PPkTRFncKe5AZgGbj9NV7j/OzSDJg47EmuBC4GPjqeo/24nJ9dmg2vO7Hj8STZDnwG+Ouq+l2/LUmahkmnbP5X4B3AniR7k3x1yn1K6mjSKZu/NoVeJE2RV9BJjTDsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiPyGh8M23+xZAl49jVe8hfASwO1Y21rvxlrn1ZVx/0Y50HD/nqSLFbVgrWtbe3+uRsvNcKwS42YtbDvtra1rT0dM3XMLml6Zm3LLmlKDLvUiJkIe5LtSX6a5ECS6wase2qSHyR5MskTSa4ZqvaKHuaSPJrkvoHrbkxyV5KnkuxL8r4Ba39q/Pd+PMkdSd425Xq3Jjmc5PEV6zYn2ZNk//j7pgFrf278d38sybeSbJxG7dXWPOxJ5oAvAx8CtgG7kmwbqPwy8Omq2gacD/zjgLVfdg2wb+CaAF8CvldVZwN/OVQPSU4BPgEsVNU5wBxw2ZTLfgPYvmrddcCDVXUm8OB4eajae4BzqurdwM+A66dU+xXWPOzAe4EDVfV0VR0F7gR2DlG4qg5V1SPjx79h9A/+lCFqAySZBz4M3DJUzXHddwIfZDxBZ1Udrar/HbCFdcDbk6wDTgB+Mc1iVfUj4FerVu8Ebhs/vg34yFC1q+r+qloeL/4YmJ9G7dVmIeynAM+vWD7IgIF7WZLTgfOAhwYs+0VG89z/fsCaAFuBJeDr40OIW5JsGKJwVb0AfB54DjgE/Lqq7h+i9ionVdWh8eMXgZPWoAeAjwPfHaLQLIR9zSU5Ebgb+GRVHRmo5sXA4ap6eIh6q6wD3gN8parOA37L9HZjX2F8bLyT0X84JwMbklw+RO1XU6P3nwd/DzrJDYwOJW8fot4shP0F4NQVy/PjdYNI8hZGQb+9qu4Zqi7wAeCSJM8wOnS5IMk3B6p9EDhYVS/vxdzFKPxDuAj4eVUtVdUx4B7g/QPVXumXSd4FMP5+eMjiSa4ELgY+WgNd7DILYf8JcGaSrUnWMzpZc+8QhZOE0XHrvqr6whA1X1ZV11fVfFWdzuh3/n5VDbKFq6oXgeeTnDVedSHw5BC1Ge2+n5/khPHf/0LW5gTlvcAV48dXAN8eqnCS7YwO3y6pqt8NVZeqWvMvYAejs5L/A9wwYN2/YrT79hiwd/y1Yw1+/78B7hu45rnA4vh3/3dg04C1/xl4Cngc+DfgrVOudwej8wPHGO3VXAX8OaOz8PuBB4DNA9Y+wOg81cv/5r46xN/dy2WlRszCbrykARh2qRGGXWqEYZcaYdilRhh2qRGGXWrE/wFPlnOsDF8/0gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In the above example, we sliced our tensor to obtain 100 of the 60,000 images. \n",
    "# You can also slice tensors along other axes. For example, \n",
    "# the 1st dimension is which image we are referring two,\n",
    "# while the 2nd and 3rd axis are the pixels of these images themselves.\n",
    "# For example, we could limit the images to the bottom right hand quadrant like this:\n",
    "lower_right_quadrant = train_images[:,14:,14:]\n",
    "print('Sliced tensor shape (includes all images but only the lower right hand corner of each:',\n",
    "      lower_right_quadrant.shape)\n",
    "plt.imshow(lower_right_quadrant[10], cmap=plt.cm.binary) #Display the 10th image from our sliced tensor.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ByGu747-rxb_"
   },
   "source": [
    "### Tensor Operations\n",
    "- **Element-wise**\n",
    "    - each element from one tensor added/etc to the corresponding elements\n",
    "- **Broadcasting**\n",
    "    - used for tensors of different dimensions\n",
    "    - in example below, when adding a (3,) vector to a (4,3) matrix, a copy of the vector is added to each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:06:07.126072Z",
     "start_time": "2020-02-12T00:06:07.118939Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "BalyDaI7rwso",
    "outputId": "36b199b5-0aa7-4a80-d2e4-87bc7f065e33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A - (shape(4, 3)):\n",
      " [[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]]\n",
      "\n",
      "B -  (shape(3,)):\n",
      " [1 2 3]\n",
      "\n",
      "Updated A:\n",
      " [[ 1  3  5]\n",
      " [ 4  6  8]\n",
      " [ 7  9 11]\n",
      " [10 12 14]]\n"
     ]
    }
   ],
   "source": [
    "# Example Broadcasting\n",
    "import numpy as np\n",
    "A=np.array([[ 0,  1,  2],\n",
    " [ 3,  4,  5],\n",
    " [ 6,  7,  8],\n",
    " [ 9, 10, 11]] )\n",
    "print(f'A - (shape{np.shape(A)}):\\n',A)\n",
    "B = np.array([1, 2, 3 ])\n",
    "print(f'\\nB -  (shape{np.shape(B)}):\\n',B)\n",
    "# Broadcasting B to add to A\n",
    "A += B\n",
    "print(f'\\nUpdated A:\\n',A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NuWdUhfzulNy"
   },
   "source": [
    "- **Tensor dot:**\n",
    "    - taking the dot product as in linear algebra\n",
    "    - a sum of element-wise products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:06:07.133072Z",
     "start_time": "2020-02-12T00:06:07.128022Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "XrxIRtr9umVK",
    "outputId": "7e211537-24c5-4b32-8633-413ba8d5e638"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-  (3,):\n",
      " [1 2 3]\n",
      "\n",
      "B.B - ():\n",
      " 14\n"
     ]
    }
   ],
   "source": [
    "# Simple dot product \n",
    "B = np.array([1,2,3])\n",
    "print(f'B-  {np.shape(B)}:\\n',B)\n",
    "\n",
    "#Taking the dot product of B and itself is equivalent to\n",
    "#1*1 + 2*2 + 3*3 = 1 + 4 + 9 = 14\n",
    "BdotB = np.dot(B,B)\n",
    "print(f'\\nB.B - {np.shape(BdotB)}:\\n',BdotB)\n",
    "# np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:06:07.142148Z",
     "start_time": "2020-02-12T00:06:07.134636Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "colab_type": "code",
    "id": "_VKfO6INvbkY",
    "outputId": "9622b289-7eed-453c-e2ae-4d26760cf88a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      " [[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]] \n",
      "\n",
      "B: [1 2 3] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 8, 26, 44, 62])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More complicated example\n",
    "# Here the first element is the sum of the first row of A multiplied by B elementwise:  \n",
    "## 0*1 + 1*2 + 2*3 = 0 + 2 + 6 = 8  \n",
    "# Followed by the sum of the second row of A multiplied by B elementwise:  \n",
    "## 3*1 + 4*2 + 5*3 = 3 + 8 + 15 = 26\n",
    "# and so on.\n",
    "A = np.array(range(12)).reshape(4,3)\n",
    "print('A:\\n', A, '\\n')\n",
    "\n",
    "B = np.array([1,2,3])#.reshape(1, -1)\n",
    "print('B:', B, '\\n')\n",
    "\n",
    "np.dot(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Using Keras for Text Analysis\n",
    "Preprocessing Text with Keras\n",
    "Link for Learn.co Keras Lab\n",
    "\n",
    "The Keras Lab uses a neural network to analyze the text inside of filed bank complaints.\n",
    "The complaint's text preprocessing in this lab involves several steps:\n",
    "create word vector counts ( a bag of words types of representation)\n",
    "Change category labels to integers\n",
    "Train-test-split the processed text.\n",
    "1\n",
    "import matplotlib.pyplot as plt\n",
    "2\n",
    "import pandas as pd\n",
    "3\n",
    "import numpy as np\n",
    "4\n",
    "import random\n",
    "5\n",
    "​\n",
    "6\n",
    "from sklearn import preprocessing\n",
    "7\n",
    "from sklearn.model_selection import train_test_split\n",
    "8\n",
    "​\n",
    "9\n",
    "# Keras preprocessing\n",
    "10\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "11\n",
    "from keras.utils.np_utils import to_categorical\n",
    "12\n",
    "​\n",
    "13\n",
    "# Keras neural network basics\n",
    "14\n",
    "from keras import models\n",
    "15\n",
    "from keras import layers\n",
    "16\n",
    "from keras import optimizers\n",
    "17\n",
    "​\n",
    "18\n",
    "​\n",
    "19\n",
    "# Load in data\n",
    "20\n",
    "data_url = 'https://raw.githubusercontent.com/jirvingphd/dsc-04-41-05-keras-lab-online-ds-ft-021119/solution/Bank_complaints.csv'\n",
    "21\n",
    "df = pd.read_csv(data_url)\n",
    "22\n",
    "df.head()\n",
    "executed in 7.95s, finished 19:06:08 2020-02-11\n",
    "1\n",
    "# Step 1. create word vector counts\n",
    "2\n",
    "​\n",
    "3\n",
    "complaints = df[\"Consumer complaint narrative\"] \n",
    "4\n",
    "tokenizer = Tokenizer(num_words=2000) #Initialize a tokenizer.\n",
    "5\n",
    "​\n",
    "6\n",
    "tokenizer.fit_on_texts(complaints) #Fit it to the complaints\n",
    "7\n",
    "​\n",
    "8\n",
    "sequences = tokenizer.texts_to_sequences(complaints) #Generate sequences\n",
    "9\n",
    "print('sequences type:', type(sequences))\n",
    "executed in 7.95s, finished 19:06:08 2020-02-11\n",
    "1\n",
    "one_hot_results= tokenizer.texts_to_matrix(complaints, mode='binary') #Similar to sequences, but returns a numpy array\n",
    "2\n",
    "print('one_hot_results type:', type(one_hot_results))\n",
    "3\n",
    "​\n",
    "4\n",
    "word_index = tokenizer.word_index #Useful if we wish to decode (more explanation below)\n",
    "5\n",
    "​\n",
    "6\n",
    "print('Found %s unique tokens.' % len(word_index)) #Tokens are the number of unique words across the corpus\n",
    "7\n",
    "​\n",
    "8\n",
    "​\n",
    "9\n",
    "print('Dimensions of our coded results:', np.shape(one_hot_results)) #Our coded data\n",
    "executed in 7.95s, finished 19:06:08 2020-02-11\n",
    "1\n",
    "reverse_index = {v:k for k,v in word_index.items()}\n",
    "2\n",
    "comment_idx_to_preview = 19\n",
    "3\n",
    "print('Original complaint text:')\n",
    "4\n",
    "print(complaints[comment_idx_to_preview])\n",
    "5\n",
    "print('\\n\\n')\n",
    "6\n",
    "​\n",
    "7\n",
    "#The reverse_index cell block above must be complete in order for this cell block to successively execute.\n",
    "8\n",
    "decoded_review = ' '.join([reverse_index.get(i) for i in sequences[comment_idx_to_preview]])\n",
    "9\n",
    "# print('Decoded review from Tokenizer:')\n",
    "10\n",
    "# print(decoded_review)\n",
    "executed in 7.95s, finished 19:06:08 2020-02-11\n",
    "1\n",
    "# Step 2: conveting descriptive categories into integers\n",
    "2\n",
    "​\n",
    "3\n",
    "product = df[\"Product\"]\n",
    "4\n",
    "​\n",
    "5\n",
    "le = preprocessing.LabelEncoder() #Initialize. le used as abbreviation fo label encoder\n",
    "6\n",
    "le.fit(product)\n",
    "7\n",
    "# print(\"Original class labels:\")\n",
    "8\n",
    "# print(list(le.classes_))\n",
    "9\n",
    "# print('\\n')\n",
    "10\n",
    "product_cat = le.transform(product)  \n",
    "11\n",
    "#list(le.inverse_transform([0, 1, 3, 3, 0, 6, 4])) #If you wish to retrieve the original descriptive labels post production\n",
    "12\n",
    "​\n",
    "13\n",
    "# print('New product labels:')\n",
    "14\n",
    "# print(product_cat)\n",
    "15\n",
    "# print('\\n')\n",
    "16\n",
    "​\n",
    "17\n",
    "# print('One hot labels; 7 binary columns, one for each of the categories.') #Each row will be all zeros except for the category for that observation.\n",
    "18\n",
    "product_onehot = to_categorical(product_cat)\n",
    "19\n",
    "# print(product_onehot)\n",
    "20\n",
    "# print('\\n')\n",
    "21\n",
    "# print('One hot labels shape:')\n",
    "22\n",
    "# print(np.shape(product_onehot))\n",
    "23\n",
    "​\n",
    "24\n",
    "# Step 3. Train-test-split\n",
    "25\n",
    "import random\n",
    "26\n",
    "random.seed(123)\n",
    "27\n",
    "test_index = random.sample(range(1,10000), 1500)\n",
    "28\n",
    "​\n",
    "29\n",
    "test = one_hot_results[test_index]\n",
    "30\n",
    "train = np.delete(one_hot_results, test_index, 0)\n",
    "31\n",
    "label_test = product_onehot[test_index]\n",
    "32\n",
    "label_train = np.delete(product_onehot, test_index, 0)\n",
    "33\n",
    "​\n",
    "34\n",
    "print(\"Test label shape:\", np.shape(label_test))\n",
    "35\n",
    "print(\"Train label shape:\", np.shape(label_train))\n",
    "36\n",
    "print(\"Test shape:\", np.shape(test))\n",
    "37\n",
    "print(\"Train shape:\", np.shape(train))\n",
    "executed in 7.95s, finished 19:06:08 2020-02-11\n",
    "1\n",
    "# Building neural network\n",
    "2\n",
    "model = models.Sequential()\n",
    "3\n",
    "model.add(layers.Dense(50, activation='relu', input_shape=(2000,))) \n",
    "4\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "5\n",
    "model.add(layers.Dense(7, activation='softmax')) # output layer with units = # of classes\n",
    "6\n",
    "​\n",
    "7\n",
    "# Compil the network\n",
    "8\n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "executed in 7.94s, finished 19:06:08 2020-02-11\n",
    "Building/Compilng the neural network\n",
    "For neural network:\n",
    "\n",
    "Use 2 hidden layers with the relu activation. layer one =50 units, layer two= 25\n",
    "Becuase we are doing multiclass (7 classes) problem, our final layer will use a softmax classifier to output 7 class probabilities per case.\n",
    "For compiling then model:\n",
    "\n",
    "Loss function: 'categorical_crossentropy`\n",
    "Optimizer: stochastic gradient descent 'SGD'\n",
    "metric: 'accuracy'\n",
    "Fit fitting:\n",
    "\n",
    "Use 120 epochs\n",
    "use 256 batch size\n",
    "1\n",
    "history = model.fit(train,\n",
    "2\n",
    "                    label_train,\n",
    "3\n",
    "                    epochs=120,\n",
    "4\n",
    "                    batch_size=256)\n",
    "executed in 7.94s, finished 19:06:08 2020-02-11\n",
    "Visualizing and Evaluating Results\n",
    "1\n",
    "# Plotting the results from history\n",
    "2\n",
    "import matplotlib.pyplot as plt \n",
    "3\n",
    "​\n",
    "4\n",
    "history_dict = history.history\n",
    "5\n",
    "loss_values = history_dict['loss']\n",
    "6\n",
    "acc_values = history_dict['acc']\n",
    "7\n",
    "# If we used a validation_set, could also plot:\n",
    "8\n",
    "# val_acc_values = history_dict['val_acc']\n",
    "9\n",
    "# val_loss_values = history_dict['val_loss']\n",
    "10\n",
    "​\n",
    "11\n",
    "​\n",
    "12\n",
    "​\n",
    "13\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "14\n",
    "fig,ax = plt.subplots(2,1, sharex=True, figsize=(6,6))\n",
    "15\n",
    "ax[0].set_title('Training Results')\n",
    "16\n",
    "ax[0].plot(epochs, loss_values, 'g', label='Training loss')\n",
    "17\n",
    "# ax[0].plot(epochs, val_loss_values,'b',label='Validation loss')\n",
    "18\n",
    "# ax[0].set_title('Training loss')\n",
    "19\n",
    "# ax[0].set_xlabel('Epochs')\n",
    "20\n",
    "ax[0].set_ylabel('Loss')\n",
    "21\n",
    "ax[0].legend()\n",
    "22\n",
    "​\n",
    "23\n",
    "​\n",
    "24\n",
    "ax[1].plot(epochs, acc_values,'r', label='Training Acc')\n",
    "25\n",
    "# ax[0].plot(epochs, val_acc_values,'b',label='Validation Acc')\n",
    "26\n",
    "​\n",
    "27\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "28\n",
    "ax[1].legend()\n",
    "29\n",
    "plt.tight_layout()\n",
    "30\n",
    "plt.show()\n",
    "31\n",
    "​\n",
    "executed in 7.94s, finished 19:06:08 2020-02-11\n",
    "1\n",
    "​\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
