{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 25: Complete Data Science Project with Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- Repeat the Mod 1 Project analysis in a streamlined way.\n",
    "\n",
    "- Learn about `pandas_profiling` for quick and easy EDA (don't use on Mod Projects please).\n",
    "\n",
    "- Intro to the idea of pipelines / programmatic construction of models\n",
    "\n",
    "- Learn about [Variance Inflation Factor](https://etav.github.io/python/vif_factor_python.html) and how to use it to address multicollinearity. ( [Wikipedia: VIF](https://en.wikipedia.org/wiki/Variance_inflation_factor))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions?\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Work Tracker (How long did the project take me?):**\n",
    "- Start: 12/10/19 ~8:45pm \n",
    "- End: 12/10/19 11:00 pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fsds_1007219  v0.4.45 loaded.  Read the docs: https://fsds.readthedocs.io/en/latest/ \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_ffd72830_1c31_11ea_9768_acde48001122\" ><caption>Loaded Packages and Handles</caption><thead>    <tr>        <th class=\"col_heading level0 col0\" >Handle</th>        <th class=\"col_heading level0 col1\" >Package</th>        <th class=\"col_heading level0 col2\" >Description</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_ffd72830_1c31_11ea_9768_acde48001122row0_col0\" class=\"data row0 col0\" >dp</td>\n",
       "                        <td id=\"T_ffd72830_1c31_11ea_9768_acde48001122row0_col1\" class=\"data row0 col1\" >IPython.display</td>\n",
       "                        <td id=\"T_ffd72830_1c31_11ea_9768_acde48001122row0_col2\" class=\"data row0 col2\" >Display modules with helpful display and clearing commands.</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_ffd72830_1c31_11ea_9768_acde48001122row1_col0\" class=\"data row1 col0\" >fs</td>\n",
       "                        <td id=\"T_ffd72830_1c31_11ea_9768_acde48001122row1_col1\" class=\"data row1 col1\" >fsds_100719</td>\n",
       "                        <td id=\"T_ffd72830_1c31_11ea_9768_acde48001122row1_col2\" class=\"data row1 col2\" >Custom data science bootcamp student package</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_ffd72830_1c31_11ea_9768_acde48001122row2_col0\" class=\"data row2 col0\" >mpl</td>\n",
       "                        <td id=\"T_ffd72830_1c31_11ea_9768_acde48001122row2_col1\" class=\"data row2 col1\" >matplotlib</td>\n",
       "                        <td id=\"T_ffd72830_1c31_11ea_9768_acde48001122row2_col2\" class=\"data row2 col2\" >Matplotlib's base OOP module with formatting artists</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_ffd72830_1c31_11ea_9768_acde48001122row3_col0\" class=\"data row3 col0\" >plt</td>\n",
       "                        <td id=\"T_ffd72830_1c31_11ea_9768_acde48001122row3_col1\" class=\"data row3 col1\" >matplotlib.pyplot</td>\n",
       "                        <td id=\"T_ffd72830_1c31_11ea_9768_acde48001122row3_col2\" class=\"data row3 col2\" >Matplotlib's matlab-like plotting module</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_ffd72830_1c31_11ea_9768_acde48001122row4_col0\" class=\"data row4 col0\" >np</td>\n",
       "                        <td id=\"T_ffd72830_1c31_11ea_9768_acde48001122row4_col1\" class=\"data row4 col1\" >numpy</td>\n",
       "                        <td id=\"T_ffd72830_1c31_11ea_9768_acde48001122row4_col2\" class=\"data row4 col2\" >scientific computing with Python</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_ffd72830_1c31_11ea_9768_acde48001122row5_col0\" class=\"data row5 col0\" >pd</td>\n",
       "                        <td id=\"T_ffd72830_1c31_11ea_9768_acde48001122row5_col1\" class=\"data row5 col1\" >pandas</td>\n",
       "                        <td id=\"T_ffd72830_1c31_11ea_9768_acde48001122row5_col2\" class=\"data row5 col2\" >High performance data structures and tools</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_ffd72830_1c31_11ea_9768_acde48001122row6_col0\" class=\"data row6 col0\" >sns</td>\n",
       "                        <td id=\"T_ffd72830_1c31_11ea_9768_acde48001122row6_col1\" class=\"data row6 col1\" >seaborn</td>\n",
       "                        <td id=\"T_ffd72830_1c31_11ea_9768_acde48001122row6_col2\" class=\"data row6 col2\" >High-level data visualization library based on matplotlib</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1111f22e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install -U fsds_100719\n",
    "from fsds_100719.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import statsmodels.api as sms\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set Display options\n",
    "pd.set_option('display.precision',3)\n",
    "pd.set_option('display.max_columns',0)\n",
    "\n",
    "## Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7129300520</td>\n",
       "      <td>10/13/2014</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.511</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6414100192</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.721</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5631500400</td>\n",
       "      <td>2/25/2015</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.738</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2487200875</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.521</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1954400510</td>\n",
       "      <td>2/18/2015</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.617</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        date     price  ...     long  sqft_living15  sqft_lot15\n",
       "0  7129300520  10/13/2014  221900.0  ... -122.257           1340        5650\n",
       "1  6414100192   12/9/2014  538000.0  ... -122.319           1690        7639\n",
       "2  5631500400   2/25/2015  180000.0  ... -122.233           2720        8062\n",
       "3  2487200875   12/9/2014  604000.0  ... -122.393           1360        5000\n",
       "4  1954400510   2/18/2015  510000.0  ... -122.045           1800        7503\n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = fs.datasets.load_mod1_proj()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRUB / EXPLORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['id','date','view']\n",
    "df.drop(drop_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pandas_profiling.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace Values\n",
    "replace_data = {'sqft_basement':('?',\"0.0\")}\n",
    "\n",
    "for col,replace in replace_data.items():\n",
    "    df[col] = df[col].replace(replace[0],replace[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Null Values\n",
    "fill_data = {'waterfront':0,\n",
    "            'yr_renovated':0}\n",
    "\n",
    "for col,val in fill_data.items():\n",
    "    df[col] = df[col].fillna(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recast Columns\n",
    "recast_cols = {'sqft_basement':'float',\n",
    "              'waterfront':'int'}\n",
    "\n",
    "for col,dtype in recast_cols.items():\n",
    "    df[col] = df[col].astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas_profiling.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = '+'.join(df.drop(target,axis=1).columns)\n",
    "# col ='bedrooms'\n",
    "# features = features.replace(col,f\"C({col})\")\n",
    "# 'price~'+features\n",
    "cols_to_use= list(df.columns)\n",
    "exclude_cols=['']\n",
    "[cols_to_use.remove(ecol) for ecol in exclude_cols if ecol in cols_to_use]\n",
    "cols_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols= list(df.columns)\n",
    "cols.remove('price')\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sms\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "\n",
    "def make_ols_f(df,target = 'price',cat_cols=[], exlude_cols=[], cols_to_use=None, display_summary=False ):\n",
    "    import statsmodels.api as sms\n",
    "    import statsmodels.formula.api as smf\n",
    "    \"\"\"Create and fit a statsmodels formula api ols model.\n",
    "    \n",
    "    Args\n",
    "        df (Frame): data for ols\n",
    "        target (str): name of target column\n",
    "        cat_cols (list of str): columns to treat as categories (i.e. \"target+C(col)\")\n",
    "        cols_to_use (list of str): \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(cat_cols,str):\n",
    "        cat_cols=[cat_cols]\n",
    "        \n",
    "    if cols_to_use is None:\n",
    "        cols_to_use=list(df.drop(target,axis=1).columns)\n",
    "        \n",
    "    ## Remove exclude cols    \n",
    "    [cols_to_use.remove(ecol) for ecol in exclude_cols if ecol in cols_to_use]\n",
    "\n",
    "    ## Create Feature List\n",
    "    features = '+'.join(cols_to_use)\n",
    "    \n",
    "    ## Make cat_cols into categories\n",
    "    for col in cat_cols:\n",
    "        features = features.replace(col,f\"C({col})\")\n",
    "            \n",
    "    ## Construct formula \n",
    "    formula = target+'~'+features\n",
    "    \n",
    "    model = smf.ols(formula=formula,data=df).fit()\n",
    "    \n",
    "    if display_summary:\n",
    "        display(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = make_ols_f(df,'price',['bedrooms','zipcode'])\n",
    "# smf.ols()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "def diagnose_model(model):\n",
    "    fig,ax= plt.subplots(ncols=2,figsize=(10,5))\n",
    "    resid = model.resid \n",
    "    sms.qqplot(data=resid, dist=stats.distributions.norm,fit=True,\n",
    "              line='45',ax=ax[0])\n",
    "    \n",
    "    ax[1].scatter(x=np.linspace(0,1,len(resid)),y=resid)\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "    \n",
    "diagnose_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How does our model look? \n",
    "- What haven't we addressed yet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revised Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrub 2: Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(col):\n",
    "    \"\"\"Use scipy to calcualte absoliute Z-scores \n",
    "    and return boolean series where True indicates it is an outlier\n",
    "    Args:\n",
    "        col (Series): a series/column from your DataFrame\n",
    "    Returns:\n",
    "        idx_outliers (Series): series of  True/False for each row in col\n",
    "        \n",
    "    Ex:\n",
    "    >> idx_outs = find_outliers(df['bedrooms'])\n",
    "    >> df_clean = df.loc[idx_outs==False]\"\"\"\n",
    "    from scipy import stats\n",
    "    z = np.abs(stats.zscore(col))\n",
    "    idx_outliers = np.where(z>3,True,False)\n",
    "    return idx_outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_outliers_Z(df,col):\n",
    "    \"\"\"Use scipy to calcualte absoliute Z-scores \n",
    "    and return boolean series where True indicates it is an outlier\n",
    "    Args:\n",
    "        col (Series): a series/column from your DataFrame\n",
    "    Returns:\n",
    "        idx_outliers (Series): series of  True/False for each row in col\n",
    "        \n",
    "    Ex:\n",
    "    >> idx_outs = find_outliers(df['bedrooms'])\n",
    "    >> df_clean = df.loc[idx_outs==False]\"\"\"\n",
    "    from scipy import stats\n",
    "\n",
    "    col = df[col]\n",
    "    z = np.abs(stats.zscore(col))\n",
    "    idx_outliers = np.where(z>3,True,False)\n",
    "    return idx_outliers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers_IQR(df,col):\n",
    "    \"\"\"Use Pandas.describe() to calculate outleirs according to Tukey's method.\n",
    "    AKA Interquartile Range Removal.\n",
    "    \n",
    "    Args:\n",
    "        df (Frame): dataframe with data\n",
    "        col (str): column in df to test\n",
    "        \n",
    "    Returns:\n",
    "        idx_outliers (Series): series of  True/False for each row in col\n",
    "    \"\"\"\n",
    "\n",
    "    res = df[col].describe()\n",
    "\n",
    "    IQR = res['75%'] - res['25%']\n",
    "    lower_limit = res['25%']-(IQR*1.5)\n",
    "    upper_limit = res['75%']+(IQR*1.5)\n",
    "\n",
    "\n",
    "    idx_outliers = (df[col]<upper_limit) & (df[col]>lower_limit)\n",
    "    return ~idx_outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test outlier removal differences\n",
    "outliers_z = find_outliers_Z(df,'bedrooms')\n",
    "outliers_iqr = find_outliers_IQR(df,'bedrooms')\n",
    "\n",
    "print(len(df))\n",
    "outliers_z.sum(),outliers_iqr.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'bedrooms'\n",
    "\n",
    "axZ =df.loc[outliers_z==False].plot(kind='scatter',x=col,y='price')\n",
    "axZ.set_title('Z Score')\n",
    "\n",
    "axIQR = df.loc[outliers_iqr==False].plot(kind='scatter',x=col,y='price')\n",
    "axIQR.set_title('IQR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identify and remove outliers\n",
    "df_outliers_Z = pd.DataFrame()\n",
    "df_outliers_IQR = pd.DataFrame()\n",
    "\n",
    "for col in df.columns: #['bedrooms','price']:\n",
    "    \n",
    "    df_outliers_Z[col] = find_outliers_Z(df,col)\n",
    "    df_outliers_IQR[col] = find_outliers_IQR(df,col)\n",
    "    \n",
    "idx_outs_Z = df_outliers_Z.any(axis=1)\n",
    "idx_outs_IQR = df_outliers_IQR.any(axis=1)\n",
    "\n",
    "print(idx_outs_Z.sum()*100/len(idx_outs_Z),idx_outs_IQR.sum()/len(idx_outs_IQR)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[idx_outs_Z==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.loc[idx_outs_Z==True].describe())\n",
    "# display(df.loc[idx_outs_IQR==False].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[idx_outs_Z==False]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Test out Revised Model\n",
    "model = make_ols_f(df,'price',['grade','zipcode'],display_summary=True)\n",
    "\n",
    "diagnose_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 = model.rsquared\n",
    "\n",
    "# VIF = 1 / (1 - R2)\n",
    "# VIF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore 2: Multicollinearity with VIF\n",
    "\n",
    "> $\\large V.I.F. = \\frac{1}{(1 - R^2)} $<br>\n",
    "- [VIF (Variance Inflation Factor)](https://etav.github.io/python/vif_factor_python.html) \n",
    "- [Wikipedia: VIF](https://en.wikipedia.org/wiki/Variance_inflation_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['zipcode']\n",
    "model_target='price'\n",
    "\n",
    "def vif_ols(df,exclude_col = None, cat_cols = ['grade','zipcode']):\n",
    "    # let's check each column, build a model and get the r2\n",
    "    vif_scores = [['Column','VIF','R2']]\n",
    "\n",
    "    if exclude_col is not None:\n",
    "        df = df.drop(exclude_col,axis=1)\n",
    "        \n",
    "    for column in df.columns:\n",
    "        columns_to_use = df.drop(columns=[column]).columns\n",
    "        target = column\n",
    "        linreg = make_ols_f(df, target=target, cat_cols=cat_cols,cols_to_use=columns_to_use)\n",
    "        R2 = linreg.rsquared\n",
    "        VIF = 1 / (1 - R2)\n",
    "    #     print(f\"VIF for {column} = {VIF}\")\n",
    "        vif_scores.append([column, VIF, R2])\n",
    "\n",
    "    res = fs.ds.list2df(vif_scores,index_col='Column')\n",
    "    res.sort_values('R2',ascending=False,inplace=True)\n",
    "    \n",
    "    return res\n",
    "\n",
    "res = vif_ols(df,exclude_col='price',)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['use'] = res['VIF']<5\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[res['use']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_use = df[res[res['use']].index]\n",
    "df_use.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = vif_ols(df_use)\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_use['price'] = df['price'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = make_ols_f(df_use,cat_cols=['grade','zipcode'])\n",
    "display(model.summary())\n",
    "diagnose_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = make_ols_f(df,target='price',cat_cols=['grade','zipcode'],exlude_cols=['floors'])\n",
    "display(model2.summary())\n",
    "diagnose_model(model2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train test spit\n",
    "cat_cols = ['grade','zipcode']\n",
    "exclude_cols=['floors']\n",
    "target = 'price'\n",
    "exclude_cols.append(target)\n",
    "print(exclude_cols)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(exclude_cols,axis=1)\n",
    "y= df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "df_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "df_train[target] = y_train\n",
    "\n",
    "df_test = pd.DataFrame(X_test, columns=X.columns)\n",
    "df_test[target] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = make_ols_f(df_use,target,cat_cols,exclude_cols)\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(df_train['price'],model3.predict(df_train))\n",
    "# r2_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, df_train, df_test):\n",
    "    from sklearn.metrics import r2_score\n",
    "    \n",
    "    res=[['Data','R2']]\n",
    "    y_hat_train = model.predict(df_train)\n",
    "    y_hat_test = model.predict(df_test)\n",
    "    \n",
    "    res.append(['Train',r2_score(df_train['price'],y_hat_train)])\n",
    "    res.append(['Test',r2_score(df_test['price'],y_hat_test)])\n",
    "    \n",
    "    return fs.ds.list2df(res)\n",
    "        \n",
    "    \n",
    "validate_model(model3,df_train,df_test)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
