{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "SWBAT:\n",
    "\n",
    "- Describe the use of confidence intervals;\n",
    "- Construct confidence intervals for different types of distributions:\n",
    "    - normal\n",
    "    - $t$\n",
    "    - binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $z$-Tables\n",
    "\n",
    "Let's start with the notion of a [$z$-table](http://z-table.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuition\n",
    "\n",
    "Because sample statistics are imperfect representations of the true population values, it is often appropriate to state these estimates with **confidence intervals**.\n",
    "\n",
    "Suppose I weigh a sample of 50 jellybeans from a population of 10000 and find the average weight to be 1.25 grams. Can I take this figure to be a good estimate of the average weight over the whole *population* of jelly beans?\n",
    "\n",
    "In a word, yes. (What else do I have to go on!?) But what I want now is a more or less precise way of indicating that this figure, though likely close to the real population mean, is inexact.\n",
    "\n",
    "Natural idea: I'll say I'm confident that the real population value lies in some neighborhood or *interval* around the figure I obtained for my sample.\n",
    "\n",
    "Notice that:\n",
    "\n",
    "- The larger my sample, the more confident I may be about the sample's representativeness for the whole population;\n",
    "- The larger I make the interval, the more confident I may be about the true population value falling within it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "Here's another example: Suppose our Indian correspondent (or David Attenborough) takes several hundred measurements of parrot beak lengths in the Ganges river basin and calculates (correctly!) an average beak length of 9cm. He reports this measure by saying that the 90%-confidence interval is (8.6, 9.4).\n",
    "\n",
    "This does NOT mean that the true population mean beak length has a 90% chance of being somewhere between 8.6cm and 9.4cm. After all, the true mean either falls in that range or it doesn't. The notion of probability *here* doesn't seem to make much sense. Rather, what our correspondent means is that, if we were to conduct the same measuring experiment many times, constructing intervals in the same way, we should expect 90% of those intervals to contain the true population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction\n",
    "\n",
    "OK: So how do we construct these intervals?\n",
    "\n",
    "The confidence interval we construct will depend on the statistics of our sample. It will depend in particular on (i) our sample mean and (ii) our sample size.\n",
    "\n",
    "It will also depend on the underlying distribution of our data. If our data are **normally** distributed, then we can proceed as follows:\n",
    "\n",
    "Naturally, the confidence interval will be centered on our sample mean. To construct the endpoints we step out from the center with a step size equal to the standard error, $\\large\\frac{\\sigma}{\\sqrt{n}}$. The number of steps we take is determined by which level of confidence we want attached to our interval: In particular, we take $z$-many steps, where $z$ is the (two-tailed) z-score that corresponds to our chosen level of confidence.\n",
    "\n",
    "If our data are **not** normally distributed, then there are several strategies we might try, some of which ultimately depend on some connection to the normal distribution, like a strategy that appeals to the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIs for Normally Distributed Data\n",
    "\n",
    "Let's look at an example with data we assume to be normally distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A normally distributed variable with a\n",
    "# population size of 1000\n",
    "\n",
    "pop = list(stats.norm.rvs(size=1000,\n",
    "                          random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01933205582232549"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's calculate the population mean.\n",
    "\n",
    "np.mean(pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9787262077473543"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And the population standard deviation.\n",
    "\n",
    "pop_std = np.std(pop)\n",
    "pop_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we take a sample of fifty from our population, and that we want an 80%-confidence interval for our estimate of the population mean. The z-score that corresponds to an 80%-confidence interval is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2815515655446004"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = stats.norm.ppf(0.9)\n",
    "#Why do we want 0.9 here?\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17715311316172172"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "sample = np.random.choice(a=pop, size=50)\n",
    "np.mean(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_std / np.sqrt(50) * z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we'd report our estimate of the population mean as 0.177 $\\pm$ 0.177, or, equivalently, as (0, 0.354). Note that the true population mean of 0.0193 is in fact in this range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIs for Non-Normally Distributed Data\n",
    "\n",
    "One of the most commonly used strategies for dealing with non-normally distributed data is to find a way to reduce the problem to one that involves normally distributed data!\n",
    "\n",
    "[Here](https://file.scirp.org/Html/3-1240887_76758.htm) is a review article that compares several different strategies. (Note that it ultimately recommends a sort of Bayesian method. We'll get to Bayesian reasoning in a later lesson.)\n",
    "\n",
    "## $t$-Distribution\n",
    "\n",
    "![imgguiness](./img/guiness.png)\n",
    "\n",
    "We can use the normal distribution when either:\n",
    "* the population standard deviation is known\n",
    "* the sample size is greater than 30.\n",
    "\n",
    "If **neither** of these holds true, we need to use the **T-distribution**. The t-distribution is wider and has different critical values for different sample sizes.\n",
    "\n",
    "\n",
    "PDF of T-distribution: ${\\frac {\\Gamma \\left({\\frac {\\nu +1}{2}}\\right)}{{\\sqrt {\\nu \\pi }}\\,\\Gamma \\left({\\frac {\\nu }{2}}\\right)}}\\left(1+{\\frac {x^{2}}{\\nu }}\\right)^{-{\\frac {\\nu +1}{2}}}\\!$, where $\\Gamma$ denotes the [Gamma Function](https://en.wikipedia.org/wiki/Gamma_function).\n",
    "\n",
    "parameter: $\\nu > 0$ where $\\nu$ is degrees of freedom (n-1)\n",
    "\n",
    "**T distribution becomes closer to Z distribution as n increases**\n",
    "![zvt](./img/z_vs_t.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import gamma\n",
    "\n",
    "fig, ax = plt.subplots(7, figsize=(10, 20))\n",
    "\n",
    "X = np.linspace(-10, 10, 201)\n",
    "nus = np.arange(2, 9)\n",
    "y_norm = 1 / np.sqrt(2*np.pi) * np.exp(-0.5 * X**2)\n",
    "\n",
    "for j in range(7):\n",
    "    y = gamma((nus[j]+1) / 2) / (np.sqrt(np.pi*nus[j]) * gamma(nus[j] / 2)) *\\\n",
    "(1 + X**2/nus[j])**((-nus[j]+1) / 2)\n",
    "    ax[j].plot(X, y, label=fr't-Distribution, $\\nu$ = {nus[j]}')\n",
    "    ax[j].plot(X, y_norm, label='Normal Distribution')\n",
    "    ax[j].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIs for $t$-Distribution\n",
    "\n",
    "The construction of confidence intervals for the t-Distribution is similar to how they are made for the normal distribution. But instead of z-scores, we'll have t-scores. And since we don't have access to the population standard deviation, we'll make use of the sample standard deviation instead.\n",
    "\n",
    "left endpt.: $\\bar{x} - t\\times\\frac{s}{\\sqrt{n}}$ <br/>\n",
    "right endpt.: $\\bar{x} + t\\times\\frac{s}{\\sqrt{n}}$\n",
    "\n",
    "### $t$-Distribution Example\n",
    "\n",
    "You are inspecting a hardware factory and want to construct a 90% confidence interval of acceptable screw lengths. You draw a sample of 30 screws and calculate their mean length as 4.8 centimeters and the standard deviation as 0.4 centimeters. What are the bounds of your confidence interval?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 30\n",
    "mean = 4.8\n",
    "t_value = stats.t.ppf(0.95, n-1)\n",
    "margin_error = t_value * 0.4/(n**0.5)\n",
    "confidence_interval = (mean - margin_error, mean + margin_error)\n",
    "\n",
    "confidence_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn!\n",
    "\n",
    "# You're weighing walruses in the Arctic in the attempt to estimate\n",
    "# the mean weight of the Canadian walrus population. You have a sample\n",
    "# of 30 walrus weights. The mean of the sample is 2000 lbs. and the\n",
    "# standard deviation is 200 lbs. Calculate the 80%-confidence interval.\n",
    "# Calculate the 70%-confidence interval. How do they compare to the\n",
    "# normal-distribution CIs? (To calculate the latter, just use the \n",
    "# sample standard deviation.)\n",
    "\n",
    "\n",
    "n = 30\n",
    "x_bar = 2000\n",
    "s = 200\n",
    "\n",
    "t_value80 = stats.t.ppf(0.9, n-1)\n",
    "t_value70 = stats.t.ppf(0.85, n-1)\n",
    "\n",
    "margin_error80 = t_value80 * 200/(n**0.5)\n",
    "margin_error70 = t_value70 * 200/(n**0.5)\n",
    "\n",
    "conf_int80 = (x_bar - margin_error80, x_bar + margin_error80)\n",
    "conf_int70 = (x_bar - margin_error70, x_bar + margin_error70)\n",
    "\n",
    "z_score80 = stats.norm.ppf(0.9)\n",
    "z_score70 = stats.norm.ppf(0.85)\n",
    "\n",
    "error_norm80 = z_score80 * 200/(n**0.5)\n",
    "error_norm70 = z_score70 * 200/(n**0.5)\n",
    "\n",
    "conf_norm80 = (x_bar - error_norm80, x_bar + error_norm80)\n",
    "conf_norm70 = (x_bar - error_norm70, x_bar + error_norm70)\n",
    "\n",
    "print(conf_int80)\n",
    "print(conf_int70)\n",
    "print(conf_norm80)\n",
    "print(conf_norm70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binomial Distribution\n",
    "\n",
    "What if we have a binomial distribution? Suppose we have the following sample statistic:\n",
    "\n",
    "A survey of 3000 voters found that 1245 approved of the job the governor was doing. How can we express our 95%-confidence level about voter approval of the governor among _all_ voters?\n",
    "\n",
    "To solve this, we'll once again start with our sample proportion as the center of our CI and step out from it by an amount proportional to the relevant z-score.\n",
    "\n",
    "But by how much exactly? Forgoing the [proof](https://newonlinecourses.science.psu.edu/stat414/node/208/), the answer *for suitably large samples* (we're relying here on the Central Limit Theorem) is as follows:\n",
    "\n",
    "left endpt.: $\\hat{p} - z\\times\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}$ <br/>\n",
    "right endpt.: $\\hat{p} + z\\times\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}$\n",
    "\n",
    "Let's answer our original question about the voters:\n",
    "\n",
    "We have:\n",
    "\n",
    "- $\\hat{p} = \\frac{1245}{3000} = 0.415$;\n",
    "- $n = 3000$;\n",
    "- $z = 1.96$.\n",
    "\n",
    "Therefore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_hat = 0.415\n",
    "n = 3000\n",
    "z_voters = stats.norm.ppf(0.975)\n",
    "step = z_voters * np.sqrt(p_hat * (1-p_hat) / n)\n",
    "\n",
    "interval = (p_hat - step, p_hat + step)\n",
    "interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIs for Other Parameters\n",
    "\n",
    "We might be interested in constructing confidence intervals for other parameters, such as the variance. [This online course](https://newonlinecourses.science.psu.edu/stat414/) has several good examples.\n",
    "\n",
    "## A Visual Interpretation of Confidence Intervals\n",
    "\n",
    "Let's see if we can get an idea of how confidence intervals work by constructing a plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting CIs\n",
    "\n",
    "intervals = []\n",
    "for _ in range(30): # number of intervals\n",
    "    sample = np.random.choice(pop, 10) # sample size = 10\n",
    "    step = np.std(pop) / np.sqrt(10) # standard error\n",
    "    x_min = np.mean(sample) - step * z # left endpt. of interval\n",
    "    x_max = np.mean(sample) + step * z # right endpt. of interval\n",
    "    intervals.append(np.linspace(x_min, x_max, 30)) # add interval\n",
    "                                                    # to intervals\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.plot(intervals, range(30), '-') # plot intervals evenly and\n",
    "                                    # vertically\n",
    "ax.vlines(np.mean(pop), 0, 30, lw=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: turn this into a function that takes as parameters:\n",
    "# - the population\n",
    "# - sample size\n",
    "# - no. of samples / confidence intervals to plot\n",
    "# - confidence level\n",
    "\n",
    "\n",
    "def ci_plotter(pop, sample_size, num_samples, conf):\n",
    "    from scipy import stats\n",
    "    intervals = []\n",
    "    for _ in range(num_samples): # number of intervals\n",
    "        sample = np.random.choice(pop, sample_size)\n",
    "        step = np.std(pop) / np.sqrt(sample_size) # standard error\n",
    "        semi_int_size = step * stats.norm.ppf(1 - (1-conf)/2)\n",
    "        \n",
    "        x_min = np.mean(sample) - semi_int_size # left endpt. of interval\n",
    "        x_max = np.mean(sample) + semi_int_size # right endpt. of interval\n",
    "        intervals.append(np.linspace(x_min, x_max, 30)) # add interval\n",
    "                                                        # to intervals\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.plot(intervals, range(num_samples), '.') # plot intervals evenly and\n",
    "                                        # vertically\n",
    "    ax.vlines(np.mean(pop), 0, num_samples, lw=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_plotter(pop=pop, sample_size=20, num_samples=20, conf=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
