{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ByfUTZodQsND"
   },
   "source": [
    "# Sect 40: Neural Networks - Intro to Deep Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 10/30/20\n",
    "- online-ds-pt-041320"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Start By Discussing Biological Neural Networks (powerpoint)\n",
    "- Connect back to introduction from Learn\n",
    "- Demonstrate / play with Neural Network with Tensorflow Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions/ Comments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biological Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/my-best-lessons-and-code-jmi/main/Images/Brainbow-Hippocampus-rainbow-colors-large.jpg\" width=60%>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> See `sect_40_bio_neural_networks_v2.pptx` for introduction to how biological neurons work. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uceu7mnytDno"
   },
   "source": [
    "# Artificial Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlvqq-TbP5zO"
   },
   "source": [
    "    \n",
    "- **The purpose of a neural network is to model $\\hat y \\approx y$ by minimizing loss/cost functions using gradient descent.**\n",
    "\n",
    "- Neural networks are very good with unstructured data. (images, audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlvqq-TbP5zO"
   },
   "source": [
    "- **Networks are comprised of sequential layers of neurons/nodes.**\n",
    "    - Each neuron applies a **linear transformation** and an **activation function** and outputs its results to all neurons in the next layer.\n",
    "    - Minimizing Loss functions by adjusting parameters (weights and bias) of each connection using gradient descent (forward and back propagation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-introduction-to-neural-networks-online-ds-ft-100719/master/images/new_first_network_num.png\" width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlvqq-TbP5zO"
   },
   "source": [
    "- **Activation functions** control the output of a neuron.($\\hat y =f_{activation}(x)$ )\n",
    "    - Most basic activation function is sigmoid functin ($\\hat y =\\sigma(x)$)\n",
    "    - Choice of activation function controls the size/range of the output.\n",
    "    \n",
    "    \n",
    "    \n",
    "- **Linear transformations** ( $z = w^T x + b$ ) are used control the output of the activation function .\n",
    "    - where $w^T $ is the weight(/coefficient), $x$ is the input, and  $b$ is a bias. \n",
    "        - weights: \n",
    "        - bias:\n",
    "        \n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-04-40-02-introduction-to-neural-networks-online-ds-ft-021119/master/figures/log_reg.png\">\n",
    "\n",
    "\n",
    "\n",
    "- **Loss functions** ($\\mathcal{L}(\\hat y, y) $)  measure inconsistency between predicted ($\\hat y$) and actual $y$\n",
    "    - will be optimized using gradient descent\n",
    "    - defined over 1 traning sample\n",
    "    \n",
    "    \n",
    "- **Cost functions** takes the average loss over all of the samples.\n",
    "    - $J(w,b) = \\displaystyle\\frac{1}{l}\\displaystyle\\sum^l_{i=1}\\mathcal{L}(\\hat y^{(i)}, y^{(i)})$\n",
    "    - where $l$ is the number of samples\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Note On Shapes\n",
    "\n",
    "- Inputs:\n",
    "    - $n$: Number of inputs (columns) in the feature vector \n",
    "    - $l$: Number of items (rows) in the training set \n",
    "    - $m$: Number of items (rows) in the test set\n",
    "    \n",
    "    \n",
    "- Input X:\n",
    "    - Will have shape $n$ x $l$ (number of features x number of training data points/rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlvqq-TbP5zO"
   },
   "source": [
    "### Training ANNs\n",
    "- **Forward propagation** is the calculating  loss and cost functions.\n",
    "\n",
    "\n",
    "- **Back propagation** involves using gradient descent to update the values for  $w$ and $b$.\n",
    "    - $w := w- \\alpha\\displaystyle \\frac{dJ(w)}{dw}$ <br><br>\n",
    "    - $b := b- \\alpha\\displaystyle \\frac{dJ(b)}{db}$\n",
    "\n",
    "        - where $ \\displaystyle \\frac{dJ(w)}{dw}$ and $\\displaystyle \\frac{dJ(b)}{db}$ represent the *slope* of the function $J$ with respect to $w$ and $b$ respectively\n",
    "        - $\\alpha$ denote the *learning rate*. \n",
    "        \n",
    "        \n",
    "        \n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/fsds_100719_cohort_notes/master/images/neural_network_steps.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlvqq-TbP5zO"
   },
   "source": [
    "### Using the chain rule for updating parameters with sigmoid activation function example:\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-04-40-02-introduction-to-neural-networks-online-ds-ft-021119/master/figures/log_reg_deriv.png\" >\n",
    "- $\\displaystyle \\frac{dJ(w,b)}{dw_i} = \\displaystyle\\frac{1}{l}\\displaystyle\\sum^l_{i=1} \\frac{d\\mathcal{L}(\\hat y^{(i)}, y^{(i)})}{dw_i}$\n",
    " \n",
    " \n",
    "- For each training sample $1,...,l$ you'll need to compute:\n",
    "\n",
    "    - $ z^{(i)} = w^T x^ {(i)} +b $\n",
    "\n",
    "    - $\\hat y^{(i)} = \\sigma (z^{(i)})$\n",
    "\n",
    "    - $dz^{(i)} = \\hat y^{(i)}- y^{(i)}$\n",
    "\n",
    "- Then, you'll need to make update:\n",
    "\n",
    "    - $J_{+1} = - [y^{(i)} \\log (\\hat y^{(i)}) + (1-y^{(i)}) \\log(1-\\hat y^{(i)})$ (for the sigmoid function)\n",
    "\n",
    "    - $dw_{1, +1}^{(i)} = x_1^{(i)} * dz^{(i)}$\n",
    "\n",
    "    - $dw_{2, +1}^{(i)} = x_2^{(i)} * dz^{(i)}$\n",
    "\n",
    "    - $db_{+1}^{(i)} =  dz^{(i)}$\n",
    "\n",
    "    - $\\dfrac{J}{m}$, $\\dfrac{dw_1}{m}$, $\\dfrac{dw_1}{m}$, $\\dfrac{db}{m}$\n",
    "\n",
    "- After that, update: \n",
    "\n",
    "    $w_1 := w_1 - \\alpha dw_1$\n",
    "\n",
    "    $w_2 := w_2 - \\alpha dw_2$\n",
    "\n",
    "    $b := b - \\alpha db$\n",
    "\n",
    "    repeat until convergence!\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JkJpdZlv3VNe"
   },
   "source": [
    "# Intro to Keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LYecj1xvmvEU"
   },
   "source": [
    "## Keras Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LYecj1xvmvEU"
   },
   "source": [
    "- Tensors dimensions:\n",
    "    - Scalars = 0D tensors\n",
    "    - Vectors = 1D tensors\n",
    "    - Matrices = 2D tensors\n",
    "    - 3D tensors\n",
    "- A tensor is defined by 3 characteristics:\n",
    "    - rank or number of axes\n",
    "    - the shape\n",
    "    - the data type\n",
    "- Tensor basics - properties (from [here](https://pgaleone.eu/tensorflow/2018/07/28/understanding-tensorflow-tensors-shape-static-dynamic/#tensors-the-basic)):\n",
    "    - name\n",
    "    - type:\n",
    "        - tf.float32, tf.int64, tf.string\n",
    "    - rank:\n",
    "        - the number of dimension or the tensor. \n",
    "        - scalar = 0, vector = 1, etc.\n",
    "    - shape:\n",
    "\n",
    "### Important Data Manipulations in numpy\n",
    "\n",
    "- **Unrowing matrices:**\n",
    "    - e.g. turning a matrix of 790 images, which are 64 x 64 pixels and in RBG (3 colors) a (790, 64, 64, 3) matrix  into a matrix with 1 row for each image a ( 64*64*3, 790) matrix\n",
    "    - img_unrow = img.reshape(790, -1).T\n",
    "        - reshape -1 essentially means \"figure out how many, based upon the dat'\n",
    "- **Increasing the rank:**\n",
    "    - Vector with `np.shape()` returns  `(790,)`\n",
    "    - `np.reshape(vector, (1, 790))`\n",
    "- **Tensor indexling/slicing**\n",
    "    - just as python, `tensor[start_idx : end_idx]`\n",
    "    - left inclusive, right exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:11:04.784577Z",
     "start_time": "2020-10-30T22:11:04.782311Z"
    }
   },
   "outputs": [],
   "source": [
    "## UPDATE TO TENSORFLOW 2.0\n",
    "# !pip install -U tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:15:27.174725Z",
     "start_time": "2020-10-30T22:15:27.169175Z"
    }
   },
   "outputs": [],
   "source": [
    "## SET RANDOM SEETS FOR CONSISTENT RESULTS\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(321)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:15:27.832512Z",
     "start_time": "2020-10-30T22:15:27.828495Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "NbbVDhN0rDhV",
    "outputId": "4b5f722d-e72f-42bd-905b-b965aee215f8"
   },
   "outputs": [],
   "source": [
    "# Tensor indexing example using images\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:15:31.856960Z",
     "start_time": "2020-10-30T22:15:31.504857Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "NbbVDhN0rDhV",
    "outputId": "4b5f722d-e72f-42bd-905b-b965aee215f8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "digit = train_images[10] #Select an arbitrary case for our example\n",
    "\n",
    "#Checking the shape of our tensor (in this case, the image)\n",
    "print('Raw Tensor shape:', train_images.shape)\n",
    "\n",
    "#Now performing some slices of our image:\n",
    "print('Single Image shape', train_images[0].shape)\n",
    "\n",
    "\n",
    "plt.imshow(digit, cmap=plt.cm.binary) #Display an example image for context\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bu64jh4K3oKt"
   },
   "source": [
    "## Basics of Building a Neural Network with Keras:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TNk4Uz27wVZc"
   },
   "source": [
    "#### Basics of Building a Neural Network with Keras\n",
    "1. Import required modules \n",
    "2. Decide on a network architecture (have only discussed sequential thus far)\n",
    "3. Adding layers - specifying layer type, number of neurons, activation functions, and, optionally, the input shape.\n",
    "4. Compile the model:\n",
    "    - Specify optimiziers\n",
    "    - specify loss functions\n",
    "    - specify metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:11:09.455421Z",
     "start_time": "2020-10-30T22:11:09.452142Z"
    }
   },
   "outputs": [],
   "source": [
    "len(train_images), len(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:11:09.729833Z",
     "start_time": "2020-10-30T22:11:09.456909Z"
    }
   },
   "outputs": [],
   "source": [
    "## Reshape images as (num_images,-1)\n",
    "train_img_unrow = None\n",
    "test_img_unrow = None\n",
    "\n",
    "## Scale the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:17:14.442706Z",
     "start_time": "2020-10-30T22:17:14.440427Z"
    }
   },
   "outputs": [],
   "source": [
    "## check train_img_unrow shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:17:18.479994Z",
     "start_time": "2020-10-30T22:17:18.477907Z"
    }
   },
   "outputs": [],
   "source": [
    "## check out an individual array's shape from train_img_unrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:18:55.033182Z",
     "start_time": "2020-10-30T22:18:55.023560Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "## Prepare y_train and y_train using to_categorical\n",
    "y_train = None\n",
    "y_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:20:42.278829Z",
     "start_time": "2020-10-30T22:20:42.276445Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check the shape of y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "58e3B6PDzIjZ"
   },
   "source": [
    "#### 5. Training the model\n",
    "- `model.fit(X_train, y_train, epochs=20,batch_size=512,validation_data=(x_val,y_val))`\n",
    "\n",
    "    - **batches:**\n",
    "        - a set of N samples, processed independently in parallel\n",
    "        - a batch determines how many samples are fed through before back-propagation. \n",
    "        - model only updates after a batch is complete.\n",
    "        - ideally have as large of a batch as your hardware can handle without going out of memory.\n",
    "            - larger batches usually run faster than smaller ones for evaluation/prediction. \n",
    "    - **epoch:**\n",
    "        - arbitrary cutoff / \"one pass over the entire dataset\", useful for logging and periodic evaluation\n",
    "        - when using kera's `model.fit` parameters `validation_data` or `validation_split`, these evaluations run at the end of every epoch.\n",
    "        - Within Keras can add callbacksto be run at the end of an epoch. Examples of these are learning rate changes and model checkpointing (saving).\n",
    "\n",
    "    - **`history =  model.fit()` creates history object with .history attribute.**\n",
    "        - `history.history()` returns a dictionary of metrics from each epoch. \n",
    "            - `history.history['loss']` and `history.history['acc']`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:23:36.477002Z",
     "start_time": "2020-10-30T22:23:36.472005Z"
    }
   },
   "outputs": [],
   "source": [
    "## Print y_train shape\n",
    "print(y_train.shape)\n",
    "## Save the number of cols as n_classes\n",
    "n_classes = y_train.shape[1]\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:27:13.402624Z",
     "start_time": "2020-10-30T22:27:13.399439Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Ary82Ge-wfTb"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "\n",
    "## Make a Sequential Model:\n",
    "\n",
    "## Add a Hidden layer of 10 units with relu activation function\n",
    "\n",
    "## Add final layer with the number of classes in our target (use activation='softmax')\n",
    "\n",
    "## Compile with optimer as adam, loss as categorical_crossentropy,\n",
    "# and accuracy as metric\n",
    "\n",
    "\n",
    "## Check out the model's summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:27:18.965764Z",
     "start_time": "2020-10-30T22:27:18.963818Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Ary82Ge-wfTb"
   },
   "outputs": [],
   "source": [
    "# Fitting the model (10 epochs, batch size=64, test data as validation data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate ANN Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:27:55.232406Z",
     "start_time": "2020-10-30T22:27:55.230565Z"
    }
   },
   "outputs": [],
   "source": [
    "## Visualzie the training history \n",
    "\n",
    "# first make it a df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:28:03.464503Z",
     "start_time": "2020-10-30T22:28:03.462129Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_kws = dict(marker='o',ls=':')\n",
    "## Plot Losses\n",
    "\n",
    "\n",
    "## Plot accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:28:12.628523Z",
     "start_time": "2020-10-30T22:28:12.626264Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:28:16.520673Z",
     "start_time": "2020-10-30T22:28:16.518441Z"
    }
   },
   "outputs": [],
   "source": [
    "## Print CLassification Report\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:28:18.681697Z",
     "start_time": "2020-10-30T22:28:18.679565Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check y_test, and y_hat_test's shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:28:33.732917Z",
     "start_time": "2020-10-30T22:28:33.730631Z"
    }
   },
   "outputs": [],
   "source": [
    "## Lets preview some rows from y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:28:35.766374Z",
     "start_time": "2020-10-30T22:28:35.764211Z"
    }
   },
   "outputs": [],
   "source": [
    "## What does one y-value look like?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:12:05.635383Z",
     "start_time": "2020-10-30T22:12:05.631932Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:28:41.440264Z",
     "start_time": "2020-10-30T22:28:41.437972Z"
    }
   },
   "outputs": [],
   "source": [
    "## Take the .argmax(axis=1) of the y-data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:28:48.740869Z",
     "start_time": "2020-10-30T22:28:48.738299Z"
    }
   },
   "outputs": [],
   "source": [
    "## Make y_pred and y_true and y_test sklearn compatible\n",
    "y_true = None\n",
    "y_pred = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:28:50.881340Z",
     "start_time": "2020-10-30T22:28:50.879241Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use y_true,y_pred to get classification report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:28:59.616515Z",
     "start_time": "2020-10-30T22:28:59.614614Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get the confusion matrix \n",
    "\n",
    "\n",
    "## Plot the confusion Matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Next class: Deep Neural Networks\n",
    "<img src=\"https://raw.githubusercontent.com/learn-co-students/dsc-introduction-to-neural-networks-onl01-dtsc-ft-070620/master/images/Deeper_network.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlvqq-TbP5zO"
   },
   "source": [
    "## Activation Functions (will call $f_a$ here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:11:17.936935Z",
     "start_time": "2020-10-30T22:11:04.836Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlvqq-TbP5zO"
   },
   "source": [
    "- **sigmoid:**<br>\n",
    "<!-- <img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-04-40-04-deeper-neural-networks-online-ds-ft-021119/master/index_files/index_33_1.png\" width=200> -->\n",
    "    - $ f_a=\\dfrac{1}{1+ \\exp(-z)}$\n",
    "    - outputs 0 to +1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:11:17.937869Z",
     "start_time": "2020-10-30T22:11:04.838Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_activation(sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlvqq-TbP5zO"
   },
   "source": [
    "- **tanh (hyperbolic tan):**<br>\n",
    "    - $f_a = =\\dfrac{\\exp(z)- \\exp(-z)}{\\exp(z)+ \\exp(-z)}$\n",
    "    - outputs -1 to +1\n",
    "    - Generally works well in intermediate layers\n",
    "    - one of most popular functions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:11:17.938691Z",
     "start_time": "2020-10-30T22:11:04.841Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_activation(tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlvqq-TbP5zO"
   },
   "source": [
    "- **arctan**\n",
    "    -  similar qualities as tanh, but slope is more gentle than tanh\n",
    "    - outputs ~ 1.6 to 1.6\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:11:17.939662Z",
     "start_time": "2020-10-30T22:11:04.844Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_activation(arctan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlvqq-TbP5zO"
   },
   "source": [
    "-  **Rectified Linear Unit (relu):**<br>\n",
    "    - most popular activation function\n",
    "    - Activation is exactly 0 when Z <0\n",
    "    - Makes taking directives slightly cumbersome\n",
    "    - $f_a=\\max(0,z)$\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:11:17.940450Z",
     "start_time": "2020-10-30T22:11:04.846Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_activation(relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlvqq-TbP5zO"
   },
   "source": [
    "- **leaky_relu:**\n",
    "    -  altered version of relu where the activatiom is slightly negative when $z<0$\n",
    "    - $f_a=\\max(0.001*z,z)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T22:11:17.941454Z",
     "start_time": "2020-10-30T22:11:04.848Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_activation(leaky_relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u2NJkNCFN9kQ"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "My Flatiron Bootcamp Notes - Mod 4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "325px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
