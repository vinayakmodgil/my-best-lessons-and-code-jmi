{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "module_path = os.path.abspath(os.pardir)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src.piApprox import pi_approx\n",
    "import src.monty_hall as mh\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Philosophical Note\n",
    "\n",
    "Philosophers wonder about the best way to understand what probabilities are. The main division is between those who want to understand probabilities _objectively_ and those who want to understand probabilities _subjectively_.\n",
    "\n",
    "### Historical Relevance\n",
    "In the early twentieth century, the quantum theory being developed by physicists was saying that the location (etc.) of a particle could be represented by a probabilistic wave function that gave probabilities for the particle to be in one place rather than another. And this question of how to understand these probabilities reared its head. Albert Einstein argued that they could only be interpreted subjectively, but the dominant interpretation today is that there is a kind of indeterminacy in the universe itself.\n",
    "\n",
    "### Objective Probability\n",
    "The paradigmatic theory of _objective_ probability is frequentism, which says that probabilities are a measure of the long-run behvior of physical systems. To say that a die has a 1/6 chance of coming up \"6\" when tossed, for example, is to say that, in the long run as the number of tosses increases without bound, the number of \"6\"s rolled will constitute one sixth of all tosses.\n",
    "\n",
    "On this point of view, **we cannot speak meaningfully of the probability of a single event**. Once a die has been rolled, there is no non-trivial probability of its having come up \"6\" or not. Either it did (in which case the probability is 1) or it did not (in which case the probability is 0).\n",
    "\n",
    "Similarly, **we cannot speak meaningfully of the probability of a parameter having a certain value, or of a hypothesis being true**. The frequentist will reject the idea of a (meaningful) probability of a die being unfairly weighted. Either it is or it is not.\n",
    "\n",
    "\n",
    "### Subjective Probability\n",
    "The paradigmatic theory of _subjective_ probability is Bayesianism, which says that probabilities are better understood as rational _degrees of belief_. The standard of rationality is necessary here to assure that these degrees of belief will conform to the probability calculus.\n",
    "\n",
    "If probabilities are degrees of belief, then it _does_ make sense to apply them to parameters or to hypotheses. The probability of a die being unfairly weighted would simply represent what it would be rational to believe about the die with respect to its being weighted or not.\n",
    "\n",
    "Now: Crucially, what it is rational to believe about the die with respect to its being weighted or not _is a function of what we know about the die!_\n",
    "\n",
    "In particular, if we gain the evidence (or knowledge) that the die has been rolled 100 times and come up \"5\" 90 times, then this would have (or, rather, *ought, rationally, to have*) a significant impact on our degree of belief with respect to the weightedness of the die. This is the sort of idea that Thomas Bayes had.\n",
    "\n",
    "## A Famous Example\n",
    "\n",
    "Suppose some rare disease affects 1 in 100,000 people. There is a test for it, though it is imperfect: 5% of the people who have the disease will test negative and 4% of the people who don't have the disease will test positive for it. You take the test and test positive. Before the test the probability that you had the disease was only 1 in 100,000. But now, with this new information of the positive test, how should you judge the probability that you have the disease?\n",
    "\n",
    "We can use Bayes's Theorem:\n",
    "\n",
    "$\\huge P(h | e) = \\frac{P(e | h)P(h)}{P(e)}$.\n",
    "\n",
    "What are $h$ and $e$ in this case?\n",
    "\n",
    "To calculate the denominator, we'll need to make use of the **Rule of Total Evidence**: <br/><br/>\n",
    "$\\large P(e) = P(e | h_1)P(h_1) + ... + P(e | h_n)P(h_n)$\n",
    "\n",
    "In our case, there are only two possibilities: Either I have the disease or I do not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.00001 * 0.95) / (0.00001 * 0.95 + 0.04 * 0.99999)\n",
    "\n",
    "# Notice that the likelihoods (P(e | h_1) and P(e | h_2)) do NOT sum to 1!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability that I have the disease is still less than 1 in 4000!\n",
    "\n",
    "## The Monty Hall Problem\n",
    "\n",
    "Bayesian reasoning applies naturally and neatly to the famous Monty Hall Problem.\n",
    "\n",
    "The situation is this: Monty Hall, classic and original host of the TV game show \"Let's Make a Deal\", has told you, the contestant, that there is some fantastic prize behind one of three curtains. Suppose, without loss of generality, that you select Door \\#1.\n",
    "\n",
    "Now here's where the story gets interesting. Hall then shows you that the prize is NOT behind one of the other two curtains. Let's suppose, again without loss of generality he opens Door \\#2.\n",
    "\n",
    "Note a few things at this point:\n",
    "\n",
    "1. Hall will never show you what's behind the door you selected.\n",
    "2. Hall will never show you where the good prize is.\n",
    "3. \\#1 and \\#2 notwithstanding, Hall will always be able to show you what's behind one of the doors without revealing where the prize is.\n",
    "\n",
    "Then Hall asks you if you'd like to *switch* your pick to the remaining door.\n",
    "\n",
    "The question is: Do you have any reason to switch? Or do you have any reason to stick with your original choice?\n",
    "\n",
    "It is natural to reason in the following way: Either the prize is behind Door \\#1, the one I picked, or it is behind Door \\#3. Clearly, the fact that Hall opened Door \\#2 could not have had any effect on the location of the prize, so there is no reason to prefer Door \\#1 or Door \\#3. So the probability that the prize is behind either of the two remaining doors is 50%.\n",
    "\n",
    "But this reasoning is wrong! The fallciousness of this reasoning was pointed out in a magazine column in the 1980s, although the writer of the column received much criticism from many \"experts\" who were arguing that the reasoning was perfectly sound. (There's a nice article about the history here: https://priceonomics.com/the-time-everyone-corrected-the-worlds-smartest/.)\n",
    "\n",
    "The truth is that you ought to switch! The truth is that, while there is only 1 chance in 3 that the door you originally selected has the prize, there are 2 chances in 3 that the other door has the prize.\n",
    "\n",
    "Let's see if we can proceed through this puzzle in Bayesian terms.\n",
    "\n",
    "### Posterior Probability that the Prize Is Behind Your Door\n",
    "Let's calculate the posterior probability that the prize is behind Door \\#1, given the evidence that Hall shows you that it is not behind Door \\#2:\n",
    "\n",
    "What is the *prior* probability that the prize is behind Door \\#1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_1 = 1/3\n",
    "prior_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's consider the likelihood of the evidence: What is the probability that Hall would show you that it is not behind Door \\#2, given the hypothesis that the prize is behind Door \\#1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "likelihood_1 = 0.5\n",
    "likelihood_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's calculate the probability of the evidence itself:\n",
    "\n",
    "There are three salient hypotheses to consider:\n",
    "\n",
    "- $h_1$: The prize is behind Door \\#1.\n",
    "- $h_2$: The prize is behind Door \\#2.\n",
    "- $h_3$: The prize is behind Door \\#3.\n",
    "\n",
    "And our evidence is:\n",
    "\n",
    "- $e$: Hall shows you that the prize is not behind Door \\#2.\n",
    "\n",
    "We can calculate the probability as follows:\n",
    "\n",
    "$P(e) = P(e | h_1)\\times P(h_1) + P(e | h_2)\\times P(h_2) + P(e | h_3)\\times P(h_3)$.\n",
    "\n",
    "We've already made the calculation for the first term:\n",
    "\n",
    "$P(e | h_1)\\times P(h_1) = \\frac{1}{2}\\times\\frac{1}{3} = \\frac{1}{6}$.\n",
    "\n",
    "Now:\n",
    "\n",
    "The probability that Hall would show you Door \\#2, given that the prize is behind Door \\#2, is *zero*. (This is by the rules of the game.)\n",
    "\n",
    "The probability that Hall would show you Door \\#2, given that the prize is behind Door \\#3, is *one*. (Here Hall's hand would be forced, since he can, by the rules, show you neither the door that you chose (\\#1) nor the door with the prize (\\#3).)\n",
    "\n",
    "So we have:\n",
    "\n",
    "$P(e) = \\frac{1}{2}\\times\\frac{1}{3} + (0)\\times\\frac{1}{3} + (1)\\times\\frac{1}{3} = \\frac{1}{2}$.\n",
    "\n",
    "We are finally in a position to calculate the posterior! We have:\n",
    "\n",
    "$\\large P(h_1 | e) = \\frac{P(e | h_1)\\times P(h)}{P(e)} = \\frac{1 / 6}{1 / 2} = \\frac{1}{3}$.\n",
    "\n",
    "That is, our updated probability that the prize is behind Door \\#1 is just the same as the prior. It's still just $\\frac{1}{3}$.\n",
    "\n",
    "### Posterior Probability that the Prize Is Behind the Other Door\n",
    "\n",
    "The posterior probability that the prize is behind Door \\#3, given the evidence that Hall has shown you what's behind Door \\#2, ought to work out to $\\frac{2}{3}$. Let's verify this:\n",
    "\n",
    "What is the *prior* probability that the prize is behind Door \\#3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_3 = 1/3\n",
    "prior_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the likelihood: What's the probability that Hall would show you Door \\#2, given that the prize is behind Door \\#3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_3 = 1\n",
    "likelihood_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've already made our calculation of the evidence. From before we had:\n",
    "\n",
    "$P(e) = \\frac{1}{2}\\times\\frac{1}{3} + (0)\\times\\frac{1}{3} + (1)\\times\\frac{1}{3} = \\frac{1}{2}$.\n",
    "\n",
    "So now we are in a position to calculate the posterior probability that the prize is behind Door \\#3. We have:\n",
    "\n",
    "$\\large P(h_3 | e) = \\frac{P(e | h_3)\\times P(h)}{P(e)} = \\frac{1 / 3}{1 / 2} = \\frac{2}{3}$.\n",
    "\n",
    "Given that Hall shows us what's behind Door \\#2, we should now update our degree of belief that the prize is behind Door \\#3 to $\\frac{2}{3}$!\n",
    "\n",
    "### Let's use `monty_hall.py`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh.play_mh(my_sel=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh.stats_mh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swapping = []\n",
    "not_swapping = []\n",
    "for _ in range(100000):\n",
    "    swapping.append(mh.stats_mh(swap=True))\n",
    "    not_swapping.append(mh.stats_mh(swap=False))\n",
    "print(sum(swapping) / 100000)\n",
    "print(sum(not_swapping) / 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Example\n",
    "\n",
    "This comes from an excellent book, _Think Bayes_, by Allen B. Downey, who himself cites Frederick Mosteller's _Fifty Challenging Problems in Probability with Solutions_.\n",
    "\n",
    "The problem is this:\n",
    "\n",
    "\"A railroad numbers its locomotives in order 1, ..., N. One day you see a locomotive with the number 60. Estimate how many locomotives the railroad has.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihoods and Estimation\n",
    "\n",
    "The idea of using evidence (including experimental results) to guess at parameter values or at underlying distributions is very powerful, but it is an idea that doesn't make any sense under traditional (objectivist) understandings of probability. Once we move, however, to the Bayesian framework, under which probabilities are to be thought of as subjective (but rational!) degrees of belief, we can make sense of:\n",
    "\n",
    "- assigning probabilities to a single event\n",
    "- assigning probabilities to various distributions as underlying the data we've collected\n",
    "- MLE and MAP techniques\n",
    "\n",
    "## Maximum Likelihood Estimation\n",
    "\n",
    "Harry the Hat, a famous magician, gives you a coin as a gift. It looks like an ordinary penny, but you know that Harry has some trick coins in his collection, so you're curious to know whether it's fair. So you flip it five times. You get three heads and two tails. And so now, with these results, you're musing about the possible weightings of the coin.\n",
    "\n",
    "Notice that this is the reverse of a more stereotypical situation where you *know* the weighting of the coin and then calculate the probabilities of various coin-flip results. In fact this sort of problem makes sense only in a *Bayesian* context where we're allowing ourselves to assign probabilities to states of the world (the weighting of the coin, in the present case).\n",
    "\n",
    "But given this allowance, we can think about the associated ***likelihood*** as a function of the coin's weighting: $P(e | h) = P(3H, 2T | p)$, where $p$ is the probability of getting a H on one toss.\n",
    "\n",
    "A natural move to make, then, is to find where this function achieves a ***maximum*** value. And, given our understanding of combinatorics and of the Binomial Distribution, we know how to calculate the values of this function.\n",
    "\n",
    "The probability of getting three heads and two tails on five tosses, with $p$ defined as above, is:\n",
    "\n",
    "$\\binom{5}{3}\\times p^3\\times(1 - p)^2$.\n",
    "\n",
    "So let's graph this function for several values of $p$ and find where it hits its maximum value!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(0, 1, 100)\n",
    "Y = 10 * X**3 * (1-X)**2\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(X, Y)\n",
    "plt.title('Maximum Likelihood')\n",
    "plt.xlabel('p')\n",
    "plt.ylabel(f'P(3H, 2T | p)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we notice about this value of $p$ where the likelihood finds its maximum? How is it related to our sample results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculus Trick\n",
    "\n",
    "Of course, we don't have to rely on eyeballing a graph to calculate the maximum of a function. We can use an old calculus trick:\n",
    "\n",
    "Consider the maximum of a function $f$; suppose it occurs at $x = x_{0}$. Now $f'$, the derivative of $f$, tells us how that function is changing at any value of $x$. And so that means that:\n",
    "- $f'(x) > 0$ for $x < x_{0}$; and\n",
    "- $f'(x) < 0$ for $x > x_{0}$.\n",
    "\n",
    "And in particular we can show that $f'(x_{0}) = 0$. Similar reasoning shows the same fact about minima.\n",
    "\n",
    "Thus if we have a differentiable function for which we seek its maxima or minima, we just need to solve the equation $f'(x) =  0$ for $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum A Posteriori Estimation\n",
    "\n",
    "The maximum likelihood may be a good estimate of the fairness of Harry the Hat's coin, but recall that we have *no prior beliefs* about the coin's weighting.\n",
    "\n",
    "If we *do* have some prior belief about the fairness of the coin, then we can use Bayes's Rule to update our belief, and this is what ***maximum a posteriori (MAP)*** estimation is all about.\n",
    "\n",
    "Often the prior and the likelihood functions work together in such a way that the posterior will have exactly the same distribution as the prior. This is called [**conjugacy**](https://en.wikipedia.org/wiki/Conjugate_prior)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: The Worst Hitter in MLB History\n",
    "\n",
    "In this project I use a MAP technique to explore the question of who could fairly be called the worst hitter in the history of the major leagues.\n",
    "\n",
    "https://github.com/gadamico/Sports-Data/\n",
    "\n",
    "\n",
    "https://www.linkedin.com/pulse/worst-hitter-history-major-league-baseball-bayesian-approach-damico/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytically Intractable Problems and Indeterministic Approximation Methods\n",
    "\n",
    "In general, there will be infinitely many possible probability distributions responsible for the observations we've made.\n",
    "\n",
    "A Bayesian might make use of *Monte Carlo sampling* here:\n",
    "\n",
    "(i) choose some distribution-defining parameters randomly; <br/>\n",
    "(ii) calculate the likelihood of the data having come from that distribution; <br/>\n",
    "(iii) \"step\" randomly to a new set of parameter values and do (i) and (ii) again <br/>\n",
    "(iv) if the newly calculated likelihood is higher than the old, then take another \"step\" *from* those new parameter values <br/>\n",
    "(v) repeat until your likelihood isn't getting any higher.\n",
    "\n",
    "Monte Carlo sampling is often used to approximate values of definite integrals that have no analytic solution. The classic example here is [the estimation of pi](https://en.wikipedia.org/wiki/Monte_Carlo_integration#Example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's use `piApprox.py`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_approx(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses = []\n",
    "for _ in range(100):\n",
    "    guesses.append(pi_approx(100))\n",
    "np.mean(guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses = []\n",
    "for i in range(1000):\n",
    "    guesses.append(pi_approx(1000))\n",
    "np.mean(guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
